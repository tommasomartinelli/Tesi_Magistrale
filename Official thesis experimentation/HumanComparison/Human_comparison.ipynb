{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook per valutazione umana delle risposte delle due pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Valutazione su domande globali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 GraphRAG su domande globali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Selezione file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import os\n",
    "from graphrag.query.indexer_adapters import read_indexer_entities, read_indexer_reports\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.structured_search.global_search.community_context import (\n",
    "    GlobalCommunityContext,\n",
    ")\n",
    "from graphrag.query.structured_search.global_search.search import GlobalSearch\n",
    "from IPython.display import Markdown, display\n",
    "import time\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path exists and is not empty.\n"
     ]
    }
   ],
   "source": [
    "file_path = '../../output/20240925-154939/artifacts'\n",
    "\n",
    "if not os.path.exists(file_path) or not os.listdir(file_path):\n",
    "    print(\"The specified path is empty or does not exist.\")\n",
    "else:\n",
    "    print(\"The path exists and is not empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = file_path\n",
    "LANCEDB_URI = f\"{INPUT_DIR}/lancedb\"\n",
    "\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "RELATIONSHIP_TABLE = \"create_final_relationships\"\n",
    "COVARIATE_TABLE = \"create_final_covariates\"\n",
    "TEXT_UNIT_TABLE = \"create_final_text_units\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "nodes_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "relationship_df = pd.read_parquet(f\"{INPUT_DIR}/{RELATIONSHIP_TABLE}.parquet\")\n",
    "df_report = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = file_path\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "\n",
    "COMMUNITY_LEVEL = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)\n",
    "\n",
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Definizione del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"GRAPHRAG_API_KEY\"]\n",
    "llm_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "api_base = \"http://172.18.21.132:8000/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    model=llm_model,\n",
    "    api_type=OpenaiApiType.OpenAI,  \n",
    "    api_base=api_base,  \n",
    "    max_retries=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Creazione query-engine per domande globali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder = GlobalCommunityContext(\n",
    "    community_reports=reports,\n",
    "    entities=entities,  \n",
    "    token_encoder=token_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder_params = {\n",
    "    \"use_community_summary\": True,  \n",
    "    \"shuffle_data\": True,\n",
    "    \"include_community_rank\": True,\n",
    "    \"min_community_rank\": 0,\n",
    "    \"community_rank_name\": \"rank\",\n",
    "    \"include_community_weight\": True,\n",
    "    \"community_weight_name\": \"occurrence weight\",\n",
    "    \"normalize_community_weight\": True,\n",
    "    \"max_tokens\": 6000,  \n",
    "    \"context_name\": \"Reports\",\n",
    "}\n",
    "\n",
    "map_llm_params = {\n",
    "    \"max_tokens\": 1500,\n",
    "    \"temperature\": 0.0,\n",
    "    \"response_format\": {\"type\": \"json_object\"},\n",
    "}\n",
    "\n",
    "reduce_llm_params = {\n",
    "    \"max_tokens\": 1500,  \n",
    "    \"temperature\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine_global = GlobalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    max_data_tokens=6000, \n",
    "    map_llm_params=map_llm_params,\n",
    "    reduce_llm_params=reduce_llm_params,\n",
    "    allow_general_knowledge=False,  \n",
    "    json_mode=True,  \n",
    "    context_builder_params=context_builder_params,\n",
    "    concurrent_coroutines=32,\n",
    "    response_type=\"Single page\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 Funzioni per esecuzione delle query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask_question_graph_global(question):\n",
    "    try:\n",
    "        result = await search_engine_global.asearch(question)\n",
    "        answer = result.response\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question: {question}\\nException: {e}\")\n",
    "        answer = \"Error: Unable to retrieve answer.\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_global_graph(question):\n",
    "    answer = await ask_question_graph_global(question)\n",
    "    display(Markdown(f\"**Domanda:** {question}\\n\\n**Risposta:**\\n{answer}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_global_1 = \"What are the main topics covered by the data in the set of time-series papers?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What are the main topics covered by the data in the set of time-series papers?\n",
       "\n",
       "**Risposta:**\n",
       "**Main Topics Covered by the Data**\n",
       "=====================================\n",
       "\n",
       "The main topics covered by the data in the set of time-series papers include:\n",
       "\n",
       "### Time Series Forecasting\n",
       "\n",
       "Time series forecasting is a key topic covered by the data, with various models and techniques being discussed, including:\n",
       "\n",
       "* Transformers\n",
       "* LSTMs\n",
       "* Anomaly Detection\n",
       "\n",
       "These topics are supported by data references [Data: Reports (105, 371, 384, 268, 303, +more)].\n",
       "\n",
       "### Anomaly Detection\n",
       "\n",
       "Anomaly detection is another key topic, with entities such as SWAT, WADI, and AnomalyBERT being closely related [Data: Reports (384, 211, 335, 75, 164)].\n",
       "\n",
       "### Time Series Analysis\n",
       "\n",
       "Time series analysis is also a main topic covered by the data, including topics such as:\n",
       "\n",
       "* Probabilistic time series forecasting\n",
       "* Univariate time series forecasting\n",
       "* Multivariate time series forecasting\n",
       "\n",
       "These subtopics are supported by data references [Data: Reports (302, 156, 350, 240, 339)].\n",
       "\n",
       "### Machine Learning and Deep Learning\n",
       "\n",
       "The data also covers topics related to machine learning, deep learning, and neural networks, which are used in time series forecasting and analysis [Data: Reports (177, 80, 176, 126, 122, +more)].\n",
       "\n",
       "### Model Evaluation and Hyperparameter Tuning\n",
       "\n",
       "Model evaluation and hyperparameter tuning are also discussed in the data, with entities such as pretraining, validation set, and training split being related to each other [Data: Reports (248, 357, 214, 219, 296)].\n",
       "\n",
       "### Domain-Specific Applications and Task-Specific Tasks\n",
       "\n",
       "Domain-specific applications and task-specific tasks are also covered in the data, with entities such as Domain-Specific Applications and Task-Specific Task being related to each other [Data: Reports (246, 88, 296, 309, 101)].\n",
       "\n",
       "### Data Preprocessing and Visualization\n",
       "\n",
       "The data also touches on topics related to data preprocessing, data augmentation, and data visualization [Data: Reports (341, 276, 221, 365, 79)].\n",
       "\n",
       "### Other Relevant Topics\n",
       "\n",
       "Other relevant topics covered by the data include:\n",
       "\n",
       "* Time series modeling\n",
       "* Time series patterns\n",
       "* Time series tokenization\n",
       "* Seasonal patterns\n",
       "* Multivariate forecasting\n",
       "* Recommender systems\n",
       "* Time series visualization\n",
       "* Time series classification\n",
       "* Time series clustering\n",
       "\n",
       "These topics are supported by data references [Data: Reports (367, 158, 327, 358, 287, +more)].\n",
       "\n",
       "Note that the above list is not exhaustive, and there may be other topics covered by the data that are not mentioned here."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await test_global_graph(question_global_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 RAG Tradizionale su domande globali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Definizione dell'embedder per pipeline Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEmbeddings(Embeddings):\n",
    "    def __init__(self, endpoint_url):\n",
    "        self.endpoint_url = endpoint_url\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            payload = {\n",
    "                \"input\": text,\n",
    "                \"model\": \"intfloat/multilingual-e5-large-instruct\"\n",
    "            }\n",
    "            response = requests.post(f\"{self.endpoint_url}/embeddings\", json=payload)\n",
    "            if response.status_code == 200:\n",
    "                embedding = response.json()['data'][0]['embedding']\n",
    "                embeddings.append(embedding)\n",
    "            else:\n",
    "                raise Exception(f\"Errore nell'embedder: {response.text}\")\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.embed_documents([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = CustomEmbeddings(endpoint_url=\"http://172.18.21.138:80/v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Realizzazione della pipeline di RAG tradizionale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "document_paths = glob.glob('../input/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "documents = []\n",
    "for file_path in document_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        documents.append(Document(page_content=content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di documenti caricati: 9\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numero di documenti caricati: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero totale di chunk: 718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,       \n",
    "    chunk_overlap=200,     \n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Numero totale di chunk: {len(docs)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs, embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di vettori indicizzati: 718\n"
     ]
    }
   ],
   "source": [
    "num_vectors = vectorstore.index.ntotal\n",
    "print(f\"Numero di vettori indicizzati: {num_vectors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Definizione del LLM con apposito prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a knowledgeable assistant specialized in answering questions based solely on the provided context. Provide a detailed and well-structured answer, including all relevant information from the context. Ensure your response is comprehensive, faithful to the context, and presented in clear, well-formed sentences. Do not add any information that is not present in the context. If the answer is not explicitly stated in the context, respond with \"I don't know.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLLM(LLM):\n",
    "    endpoint_url: str\n",
    "    model_name: str = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "    temperature: float = 0.0\n",
    "    max_tokens: int = 1500\n",
    "    repetition_penalty: float = 1.2\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom_llm\"\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        payload = {\n",
    "            \"prompt\": prompt,\n",
    "            \"model\": self.model_name,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "            \"repetition_penalty\": self.repetition_penalty,\n",
    "            \"stop\": stop or [\"I don't know.\"],\n",
    "        }\n",
    "        print(\"Payload inviato all'API:\", payload)  \n",
    "        response = requests.post(f\"{self.endpoint_url}/completions\", json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['choices'][0]['text']\n",
    "        else:\n",
    "            raise Exception(f\"Errore nel LLM: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CustomLLM(\n",
    "    endpoint_url=\"http://172.18.21.132:8000/v1\",\n",
    "    temperature=0.0,\n",
    "    max_tokens= 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Funzioni per esecuzione delle query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask_question_naive(query):  \n",
    "    result = qa_chain({\"query\": query})  \n",
    "    answer = result['result']\n",
    "    display(Markdown(f\"**Domanda:** {query}\\n\\n**Risposta:** {answer}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_190684/398108627.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  result = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload inviato all'API: {'prompt': '\\nYou are a knowledgeable assistant specialized in answering questions based solely on the provided context. Provide a detailed and well-structured answer, including all relevant information from the context. Ensure your response is comprehensive, faithful to the context, and presented in clear, well-formed sentences. Do not add any information that is not present in the context. If the answer is not explicitly stated in the context, respond with \"I don\\'t know.\"\\n\\nContext:\\n# Categories of Time Series.\\n\\nA time series is commonly described as an ordered sequence of data points. Figure 2 illustrates various types of time series discussed in this survey, including standard time series, spatial time series, trajectories, and events. Note that trajectories and events can be regarded as time series since each data point is associated with a specific timestamp (and location), allowing for analysis using time series techniques such as anomaly detection. These time series are formulated as follows.\\n# Foundation Models for Time Series Analysis: A Tutorial and Survey\\n\\n# KDD ’24, August 25–29, 2024, Barcelona, Spain\\n\\n# 1. Introduction\\n\\nIn contrast to previous surveys, this manuscript incorporates the most extensive array of time series data types (see Table 1), spatial time series, as well as other types such as the trajectory and event. We further summarize the developmental roadmap of current TSFMs in Figure 1, in order to foster further innovations and understanding in the dynamic and ever-evolving landscape of TSFMs. In short, our major contributions lie in three aspects:\\n\\nTimeGPT was trained on, to our knowledge, the largest collection of publicly available time series, collectively encompassing over 100 billion data points. This training set incorporates time series from a broad array of domains, including finance, economics, demographics, healthcare, weather, IoT sensor data, energy, web traffic, sales, transport, and banking. Due to this diverse set of domains, the training dataset contains time series with a wide range of characteristics.\\n\\n# 2 RELATED WORKS\\n\\n# Time Series Anomaly Detection\\n\\n# 5 Pretraining Details\\n\\nWe would like our pretraining corpus to include large volumes of temporal data representing a variety of domains, trend and seasonality patterns and time granularities that ideally capture the forecasting use-cases which we are interested in serving by the deployed model. It is challenging to find a large time-series dataset that meets the volume and diversity of data needed for training our foundation model. We address this problem by sourcing the bulk of data used to train our models from three major sources: Google trends, Wiki Pageview statistics and synthetic time-series. In summary the main data sources are:\\n\\n# Google Trends\\n\\nQuestion:\\nWhat are the main topics covered by the data in the set of time-series papers?\\n\\nAnswer:\\n', 'model': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'temperature': 0.0, 'max_tokens': 500, 'repetition_penalty': 1.2, 'stop': [\"I don't know.\"]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What are the main topics covered by the data in the set of time-series papers?\n",
       "\n",
       "**Risposta:**The main topics covered by the data in the set of time-series papers appear to be related to various fields or domains, including but not limited to finance, economics, demographics, healthcare, weather, IoT sensor data, energy, web traffic, sales, transport, and banking. The text does mention that these categories were identified through the incorporation of the most extensive array of time series data types into the paper's discussion. However, it doesn't provide more details about what exactly those categories mean within their respective contexts. I do not have enough information to give you a precise description of how they relate to one another. Therefore, my best guess at providing some insight into the nature of these categories will involve describing them broadly. \n",
       "\n",
       "Finance refers to financial markets, economic indicators, stock prices, etc., while Economics encompasses macroeconomic variables, GDP growth rates, inflation rates, unemployment levels, etc. Demographics involves population size, age distribution, gender ratios, education level, income distributions, etc. Healthcare includes disease prevalence, hospital admissions, patient outcomes, medication usage, medical research findings, etc. Weather pertains to temperature readings, precipitation amounts, atmospheric pressure measurements, wind speed observations, cloud cover percentages, etc. IoT Sensor Data relates to real-time monitoring systems tracking environmental conditions, industrial equipment performance, consumer behavior, smart home devices' status updates, vehicle movement patterns, etc. Energy deals with electricity consumption patterns, renewable resource production outputs, fuel price fluctuations, power grid stability metrics, etc. Web Traffic focuses on website visits counts per hour/day/week/month; page views numbers broken down across different browsers/devices/geographic locations; bounce rate calculations indicating user engagement levels; average session duration times reflecting visitor interest periods; etc. Sales covers product demand forecasts generated via machine learning algorithms analyzing historical transaction records stored within databases managed by e-commerce platforms selling goods online worldwide today! Transport addresses passenger travel habits tracked through mobile apps showing routes taken between destinations along roads highways airports seaports railways subways buses taxis ride-sharing services bike-share programs walkability scores pedestrian infrastructure quality assessments street lighting condition evaluations noise pollution indexes air quality monitoring results traffic congestion severity ratings road safety indices accident frequency rates driver behavior analytics fleet management solutions logistics optimization strategies supply chain visibility tools route planning software package delivery scheduling systems inventory control methods warehouse automation technologies freight forwarding companies customs clearance procedures border crossing regulations trade agreements tariffs duties taxes excise fees levied upon imported/exported commodities currency exchange rates market volatility risk assessment methodologies hedging instruments futures contracts options trading derivatives securities investments portfolio"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await ask_question_naive(question_global_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Confronto su domande globali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Selezione di 5 domande globali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le 5 domande verranno sottoposte ad entrambe le pipeline, analizzandone le risposte e misurando i tempi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_global1 = \"What are the main topics covered by the data in the set of time-series papers?\"\n",
    "query_global2 = \"What types of real-world applications can benefit from models like TimeLLM, RestAD, TimeGPT, AnomalyBERT, LagLLama and the other models described?\"\n",
    "query_global3 = \"What are the main trade-offs when choosing between transformer-based models and traditional time-series models?\"\n",
    "query_global4 = \"How do anomaly detection models like AnomalyBERT, TranAD, and RestAD compare in terms of their robustness and adaptability to various types of anomalies (contextual, point, collective) across different time series domains?\"\n",
    "query_global5 = \"How does TimeGPT approach time-series forecasting?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Confronto risposte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.2.1 Prima Query globale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GraphRAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What are the main topics covered by the data in the set of time-series papers?\n",
       "\n",
       "**Risposta:**\n",
       "**Main Topics Covered by the Data**\n",
       "=====================================\n",
       "\n",
       "The main topics covered by the data in the set of time-series papers include:\n",
       "\n",
       "### Time Series Forecasting\n",
       "\n",
       "Time series forecasting is a key topic covered by the data, with various models and techniques being discussed, including:\n",
       "\n",
       "* Transformers\n",
       "* LSTMs\n",
       "* Anomaly Detection\n",
       "\n",
       "These topics are supported by data references [Data: Reports (105, 371, 384, 268, 303, +more)].\n",
       "\n",
       "### Anomaly Detection\n",
       "\n",
       "Anomaly detection is another key topic, with entities such as SWAT, WADI, and AnomalyBERT being closely related [Data: Reports (384, 211, 335, 75, 164)].\n",
       "\n",
       "### Time Series Analysis\n",
       "\n",
       "Time series analysis is also a main topic covered by the data, including topics such as:\n",
       "\n",
       "* Probabilistic time series forecasting\n",
       "* Univariate time series forecasting\n",
       "* Multivariate time series forecasting\n",
       "\n",
       "These subtopics are supported by data references [Data: Reports (302, 156, 350, 240, 339)].\n",
       "\n",
       "### Machine Learning and Deep Learning\n",
       "\n",
       "The data also covers topics related to machine learning, deep learning, and neural networks, which are used in time series forecasting and analysis [Data: Reports (177, 80, 176, 126, 122, +more)].\n",
       "\n",
       "### Model Evaluation and Hyperparameter Tuning\n",
       "\n",
       "Model evaluation and hyperparameter tuning are also discussed in the data, with entities such as pretraining, validation set, and training split being related to each other [Data: Reports (248, 357, 214, 219, 296)].\n",
       "\n",
       "### Domain-Specific Applications and Task-Specific Tasks\n",
       "\n",
       "Domain-specific applications and task-specific tasks are also covered in the data, with entities such as Domain-Specific Applications and Task-Specific Task being related to each other [Data: Reports (246, 88, 296, 309, 101)].\n",
       "\n",
       "### Data Preprocessing and Visualization\n",
       "\n",
       "The data also touches on topics related to data preprocessing, data augmentation, and data visualization [Data: Reports (341, 276, 221, 365, 79)].\n",
       "\n",
       "### Additional Topics\n",
       "\n",
       "Other topics covered by the data include:\n",
       "\n",
       "* Seasonal patterns\n",
       "* Multivariate forecasting\n",
       "* Recommender systems\n",
       "* Time series visualization\n",
       "* Time series classification\n",
       "* Time series clustering\n",
       "\n",
       "These topics are supported by data references [Data: Reports (367, 158, 327, 358, 287, +more)].\n",
       "\n",
       "Note that the above list is not exhaustive, and there may be additional topics covered by the data that are not mentioned here."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await test_global_graph(query_global1)\n",
    "\n",
    "end_time = time.time()\n",
    "time_global_graph1 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG tradizionale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload inviato all'API: {'prompt': '\\nYou are a knowledgeable assistant specialized in answering questions based solely on the provided context. Provide a detailed and well-structured answer, including all relevant information from the context. Ensure your response is comprehensive, faithful to the context, and presented in clear, well-formed sentences. Do not add any information that is not present in the context. If the answer is not explicitly stated in the context, respond with \"I don\\'t know.\"\\n\\nContext:\\n# Categories of Time Series.\\n\\nA time series is commonly described as an ordered sequence of data points. Figure 2 illustrates various types of time series discussed in this survey, including standard time series, spatial time series, trajectories, and events. Note that trajectories and events can be regarded as time series since each data point is associated with a specific timestamp (and location), allowing for analysis using time series techniques such as anomaly detection. These time series are formulated as follows.\\n# Foundation Models for Time Series Analysis: A Tutorial and Survey\\n\\n# KDD ’24, August 25–29, 2024, Barcelona, Spain\\n\\n# 1. Introduction\\n\\nIn contrast to previous surveys, this manuscript incorporates the most extensive array of time series data types (see Table 1), spatial time series, as well as other types such as the trajectory and event. We further summarize the developmental roadmap of current TSFMs in Figure 1, in order to foster further innovations and understanding in the dynamic and ever-evolving landscape of TSFMs. In short, our major contributions lie in three aspects:\\n\\nTimeGPT was trained on, to our knowledge, the largest collection of publicly available time series, collectively encompassing over 100 billion data points. This training set incorporates time series from a broad array of domains, including finance, economics, demographics, healthcare, weather, IoT sensor data, energy, web traffic, sales, transport, and banking. Due to this diverse set of domains, the training dataset contains time series with a wide range of characteristics.\\n\\n# 2 RELATED WORKS\\n\\n# Time Series Anomaly Detection\\n\\n# 5 Pretraining Details\\n\\nWe would like our pretraining corpus to include large volumes of temporal data representing a variety of domains, trend and seasonality patterns and time granularities that ideally capture the forecasting use-cases which we are interested in serving by the deployed model. It is challenging to find a large time-series dataset that meets the volume and diversity of data needed for training our foundation model. We address this problem by sourcing the bulk of data used to train our models from three major sources: Google trends, Wiki Pageview statistics and synthetic time-series. In summary the main data sources are:\\n\\n# Google Trends\\n\\nQuestion:\\nWhat are the main topics covered by the data in the set of time-series papers?\\n\\nAnswer:\\n', 'model': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'temperature': 0.0, 'max_tokens': 500, 'repetition_penalty': 1.2, 'stop': [\"I don't know.\"]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What are the main topics covered by the data in the set of time-series papers?\n",
       "\n",
       "**Risposta:** The main topics covered by the data in the set of time-series papers appear to be related to various fields or domains, including but not limited to finance, economics, demographics, healthcare, weather, IoT sensor data, energy, web traffic, sales, transport, and banking. The text does mention that these categories were identified through the incorporation of the most extensive array of time series data types into the paper's discussion. However, it doesn't provide more details about what exactly those categories mean within their respective contexts. I do not have enough information to give you a precise description of how they relate to one another. Therefore, my best guess at providing some insight into the nature of these categories will involve describing them broadly. \n",
       "\n",
       "Finance refers to financial markets, economic indicators, stock prices, etc., while Economics encompasses macroeconomic variables, GDP growth rates, inflation rates, unemployment levels, etc. Demographics involves population size, age distribution, gender ratios, education level, income distributions, etc. Healthcare includes disease prevalence, hospital admissions, patient outcomes, medication usage, medical research findings, etc. Weather pertains to temperature readings, precipitation amounts, atmospheric pressure measurements, wind speed observations, cloud cover percentages, etc. IoT Sensor Data relates to real-time monitoring systems tracking environmental conditions, industrial equipment performance, consumer behavior, smart home devices' status updates, vehicle movement patterns, etc. Energy deals with electricity consumption patterns, renewable resource production outputs, fuel price fluctuations, power grid stability metrics, etc. Web Traffic focuses on website visits counts per hour/day/week/month; page views numbers broken down across different browsers/devices/geographic locations; bounce rate calculations indicating user engagement levels; average session duration times reflecting visitor interest periods; etc. Sales covers product demand forecasts generated via machine learning algorithms analyzing historical transaction records stored within databases managed by e-commerce platforms selling goods online worldwide today! Transport addresses passenger travel habits tracked through mobile apps showing routes taken between destinations along roads highways airports seaports railways subways buses taxis ride-sharing services bike-share programs walkability scores pedestrian infrastructure quality assessments street lighting condition evaluations noise pollution indexes air quality monitoring results traffic congestion severity ratings road safety indices accident frequency rates driver behavior analytics fleet management solutions logistics optimization strategies supply chain visibility tools route planning software package delivery scheduling systems inventory control methods warehouse automation technologies freight forwarding companies customs clearance procedures border crossing regulations trade agreements tariffs duties taxes excise fees levied upon imported/exported commodities currency exchange rates market volatility risk assessment methodologies hedging instruments futures contracts options trading derivatives securities investments portfolio"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await ask_question_naive(query_global1)\n",
    "\n",
    "end_time = time.time()\n",
    "time_global_naive1 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.2.2 Seconda query globale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GraphRAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What types of real-world applications can benefit from models like TimeLLM, RestAD, TimeGPT, AnomalyBERT, LagLLama and the other models described?\n",
       "\n",
       "**Risposta:**\n",
       "# Real-World Applications of Time Series Forecasting and Anomaly Detection Models\n",
       "\n",
       "## Introduction\n",
       "\n",
       "The models described, including TimeLLM, RestAD, TimeGPT, AnomalyBERT, and LagLLama, have various real-world applications across different industries. These models can benefit applications such as demand forecasting, supply chain management, energy consumption prediction, anomaly detection, and more.\n",
       "\n",
       "## Demand Forecasting and Supply Chain Management\n",
       "\n",
       "*   **Retail**: Demand forecasting models like TimeLLM, TimeGPT, and LagLLama can benefit real-world applications such as demand forecasting in retail, supply chain management, and energy consumption prediction.\n",
       "*   **Supply Chain Management**: Time series forecasting models like TimeLLM, RestAD, and TimeGPT can benefit various real-world applications such as demand forecasting in supply chain management, energy consumption prediction in smart grids, and stock market prediction in finance.\n",
       "\n",
       "## Anomaly Detection\n",
       "\n",
       "*   **Finance**: Anomaly detection models like RestAD and AnomalyBERT can benefit real-world applications such as fraud detection in finance, quality control in manufacturing, and network intrusion detection in cybersecurity.\n",
       "*   **Manufacturing**: Anomaly detection models like AnomalyBERT and LagLLama can be applied in industries such as manufacturing, healthcare, and finance to identify unusual patterns or outliers in data, which can indicate potential issues or opportunities.\n",
       "*   **Cybersecurity**: Anomaly detection models like AnomalyBERT can benefit real-world applications such as network intrusion detection in cybersecurity, fraud detection in finance, and quality control in manufacturing.\n",
       "\n",
       "## Natural Language Processing and Text Analysis\n",
       "\n",
       "*   **Text Summarization**: Transformer-based models like TimeGPT and RestAD can be used in applications such as natural language processing, machine translation, and text summarization, where the ability to handle sequential data is essential.\n",
       "*   **Language Translation**: Language models like LagLLama can benefit real-world applications such as text summarization, sentiment analysis, and machine translation.\n",
       "*   **Sentiment Analysis**: Deep learning models like TimeGPT and AnomalyBERT can benefit real-world applications such as image recognition, speech recognition, and recommender systems.\n",
       "\n",
       "## Other Applications\n",
       "\n",
       "*   **Weather Forecasting**: Probabilistic forecasting models like Chronos can benefit real-world applications such as weather forecasting, stock market prediction, and traffic flow prediction.\n",
       "*   **Traffic Flow Prediction**: Time series analysis models like TimeGPT and LagLLama can benefit applications such as predicting traffic flow in transportation systems, analyzing climate patterns in environmental science, and understanding customer behavior in marketing.\n",
       "*   **Image Recognition**: Deep learning models like TimeGPT and AnomalyBERT can benefit real-world applications such as image recognition, speech recognition, and recommender systems.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The models described have various real-world applications across different industries. These models can benefit applications such as demand forecasting, supply chain management, energy consumption prediction, anomaly detection, and more. The specific applications and benefits of each model depend on the characteristics of the data and the requirements of the problem being addressed."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await test_global_graph(query_global2)\n",
    "\n",
    "end_time = time.time()\n",
    "time_global_graph2 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG tradizionale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload inviato all'API: {'prompt': '\\nYou are a knowledgeable assistant specialized in answering questions based solely on the provided context. Provide a detailed and well-structured answer, including all relevant information from the context. Ensure your response is comprehensive, faithful to the context, and presented in clear, well-formed sentences. Do not add any information that is not present in the context. If the answer is not explicitly stated in the context, respond with \"I don\\'t know.\"\\n\\nContext:\\n# Input statistics:\\n\\n- &lt;time series statistic 1&gt;\\n- &lt;time series statistic 2&gt; …\\n\\n# Frozen Training\\n\\n# Prompt Embeddings\\n\\n# Patch Embeddings\\n\\n# Forward\\n\\n# Backward\\n\\nFigure 2: The model framework of TIME-LLM.\\nGiven an input time series, we first tokenize and embed it via 1 patching along with a 2 customized embedding layer. 3 These patch embeddings are then reprogrammed with condensed text prototypes to align two modalities. To augment the LLM’s reasoning ability, 4 additional prompt prefixes are added to the input to direct the transformation of input patches. 5 The output patches from the LLM are projected to generate the forecasts.\\n\\n# Easy optimization\\n\\nLLMs are trained once on massive computing and then can be applied to forecasting tasks without learning from scratch. Optimizing existing forecasting models often requires significant architecture search and hyperparameter tuning (Zhou et al., 2023b).\\n\\nIn summary, LLMs offer a promising path to make time series forecasting more general, efficient, synergistic, and accessible compared to current specialized modeling paradigms. Thus, adapting these powerful models for time series data can unlock significant untapped potential.\\n\\n|Type|Methodology|Domain|References| | |\\n|---|---|---|---|---|---|\\n|Pre-trained LLM, AM, VLM|General| |Time-LLM [47], OFA [120], LLM4TS [11], PromptCast [102], TEMPO [10], LLMTime [36], Voice2Series [105], AutoTimes [63], UniTime [60]| | |\\n| | |Finance| |Yu et al. [108], Chen et al. [19], Xie et al. [100], Wimmer et al. [96]| |\\n| | |Healthcare| |Liu et al. [62]| |\\n|Generative|General| |PatchTST [68], Moirai [97], Lag-Llama [75], TimeSiam [26], Timer [64], Das et al. [24], UniTS [34], TimeGPT-1 [35], Chronos [1], MTSMAE [84]| | |\\n| | |Self-supervised|Contrastive|General: TEST [83], TimeCLR [107]| |\\n| | | |Healthcare| |METS [52]|\\n|Hybrid| |General|SimMTM [27]| | |\\n|Fully-supervised| |General|TimeXer [90], UniTS [34]| | |\\n|non-Transformer-based (MLP RNN CNN)|Self-supervised|Generative|TSMixer [30]| | |\\n| | |Contrastive|General|TF-C [115], TS2Vec [111], CLUDA [69]| |\\n|Fully-supervised| |General|TTMs [31], TimesNet [98], RWKV-TS [40]| | |\\n\\nIn both cases. TIME-LLM exhibits remarkable superiority in forecasting with limited data—a fact that becomes particularly salient when compared to GPT4TS.\\n# Published as a conference paper at ICLR 2024\\n\\n# Table 18: Efficiency comparison between model reprogramming and parameter-efficient fine-tuning (PEFT) with QLoRA (Dettmers et al., 2023) on ETTh1 dataset in forecasting two different steps ahead.\\n\\n|Length|ETTh1-96|ETTh1-96|ETTh1-96|ETTh1-336|ETTh1-336|ETTh1-336|\\n|---|---|---|\\n|Metric|Trainable Param. (M)|Mem. (MiB)|Speed(s/iter)|Trainable Param. (M)|Mem. (MiB)|Speed(s/iter)|\\n|Llama (8) QLoRA|12.60|14767|0.237|12.69|15982|0.335|\\n|Llama (8) Reprogram|5.62|11370|0.184|5.71|13188|0.203|\\n|Llama (32) QLoRA|50.29|45226|0.697|50.37|49374|0.732|\\n|Llama (32) Reprogram|6.39|32136|0.517|6.48|37988|0.632|\\n\\n# Table 19: Standard deviations of our approach and the second-best method (PatchTST) on all time series datasets for long-term forecasting.\\n\\n- TIME-LLM consistently exceeds state-of-the-art performance in mainstream forecasting tasks, especially in few-shot and zero-shot scenarios. Moreover, this superior performance is achieved while maintaining excellent model reprogramming efficiency. Thus, our research is a concrete step in unleashing LLMs’ untapped potential for time series and perhaps other sequential data.\\n\\nQuestion:\\nWhat types of real-world applications can benefit from models like TimeLLM, RestAD, TimeGPT, AnomalyBERT, LagLLama and the other models described?\\n\\nAnswer:\\n', 'model': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'temperature': 0.0, 'max_tokens': 500, 'repetition_penalty': 1.2, 'stop': [\"I don't know.\"]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What types of real-world applications can benefit from models like TimeLLM, RestAD, TimeGPT, AnomalyBERT, LagLLama and the other models described?\n",
       "\n",
       "**Risposta:** According to the given context, several real-world domains can potentially benefit from models like TimeLLM, such as finance, healthcare, and possibly others where time-series analysis plays a crucial role. Specifically, the following areas have been mentioned:\n",
       "\n",
       "* Finance: Models like Yu et al.'s work [108], Chen et al.'s work [19], Xie et al.'s work [100], and Wimmer et al.'s work [96] suggest that financial institutions could leverage models similar to TimeLLM for better decision-making.\n",
       "* Healthcare: Liu et al.'s work [62] implies that hospitals or medical organizations might find value in using models like TimeLLM for analyzing health-related time-series data.\n",
       "* General domain: Given the broad applicability of TimeLLM across various industries, it's reasonable to assume that many sectors beyond finance and healthcare could also benefit from its capabilities, although specific examples aren't provided within the given context.\n",
       "\n",
       "It's essential to note that the actual benefits and suitability of these models would depend on their implementation details, training data quality, and how they're integrated into existing workflows. However, according to the provided context, there seems to be considerable promise in applying models like TimeLLM to address challenges in diverse fields. I don't know if there are any other specific application areas mentioned outside of those listed above. \n",
       "\n",
       "The table listing pre-trained language models used for time series forecasting includes entries under 'general' but does not specify particular use-cases apart from mentioning some papers which may relate to broader topics than just one area. Therefore, further investigation into each referenced study would provide deeper insights into applicable domains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await ask_question_naive(query_global2)\n",
    "\n",
    "end_time = time.time()\n",
    "time_global_naive2 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.2.3 Terza query globale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GraphRAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What are the main trade-offs when choosing between transformer-based models and traditional time-series models?\n",
       "\n",
       "**Risposta:**\n",
       "# Choosing Between Transformer-Based Models and Traditional Time-Series Models\n",
       "\n",
       "When deciding between transformer-based models and traditional time-series models, several key trade-offs must be considered.\n",
       "\n",
       "## Complexity and Interpretability\n",
       "\n",
       "### Transformer-Based Models\n",
       "\n",
       "*   Generally more complex and computationally expensive than traditional time-series models\n",
       "*   Can handle long-range dependencies and complex patterns in time-series data\n",
       "*   May require significant computational resources and expertise for fine-tuning\n",
       "\n",
       "### Traditional Time-Series Models\n",
       "\n",
       "*   Often simpler and more interpretable than transformer-based models\n",
       "*   May struggle with complex patterns and long-range dependencies in time-series data\n",
       "*   Can be more robust and less prone to overfitting, especially when dealing with noisy or missing data\n",
       "\n",
       "## Data Requirements and Robustness\n",
       "\n",
       "### Transformer-Based Models\n",
       "\n",
       "*   Can be more data-hungry than traditional time-series models, requiring large amounts of data to train effectively\n",
       "*   May be more prone to overfitting and less robust to noise and outliers in time-series data\n",
       "*   Can be fine-tuned for specific tasks and datasets, but this may require large amounts of training data and computational resources\n",
       "\n",
       "### Traditional Time-Series Models\n",
       "\n",
       "*   Often more robust to noise and outliers in time-series data than transformer-based models\n",
       "*   Can handle missing or noisy data more effectively than transformer-based models\n",
       "*   May not be able to capture complex patterns and long-range dependencies in time-series data\n",
       "\n",
       "## Task-Specific Performance\n",
       "\n",
       "### Transformer-Based Models\n",
       "\n",
       "*   Can be used for a wide range of time-series forecasting tasks, including short-term and long-term forecasting, and can handle multiple input features and outputs\n",
       "*   May provide better performance and more accurate predictions than traditional time-series models, but this depends on the specific characteristics of the data and the task at hand\n",
       "*   May require more data and computational resources than traditional time-series models\n",
       "\n",
       "### Traditional Time-Series Models\n",
       "\n",
       "*   Often task-specific and may not perform as well on complex or non-linear time-series data\n",
       "*   Can be more robust to overfitting and can handle missing or noisy data, but may not be able to capture complex patterns and long-range dependencies in time-series data\n",
       "\n",
       "Ultimately, the choice between transformer-based models and traditional time-series models depends on the specific characteristics of the data and the goals of the analysis."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await test_global_graph(query_global3)\n",
    "\n",
    "end_time = time.time()\n",
    "time_global_graph3 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG tradizionale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload inviato all'API: {'prompt': '\\nYou are a knowledgeable assistant specialized in answering questions based solely on the provided context. Provide a detailed and well-structured answer, including all relevant information from the context. Ensure your response is comprehensive, faithful to the context, and presented in clear, well-formed sentences. Do not add any information that is not present in the context. If the answer is not explicitly stated in the context, respond with \"I don\\'t know.\"\\n\\nContext:\\nthat demand substantial computational resources and time for inference. Recent concurrent work (Dooley et al., 2023; Das et al., 2023; Rasul et al., 2023; Woo et al., 2024) also explores pretraining transformer-based models with sophisticated time-series-specific designs on a large corpus of real and (or) synthetic time series data.\\n\\n# 5.1 Architecture\\n\\nAs shown in Figure 4, we first delve into the architecture of TSFMs, including Transformer-based models, non-Transformer-based models and diffusion-based models, focusing on the underlying mechanisms that shape their capabilities, as well as how they could be applied on various time series.\\n\\n# 5.1.1 Transformer-based Models\\n\\nIn addition to conventional time series data, the Transformer architecture has demonstrated efficacy across a diverse array of temporal datasets, such as trajectory and healthcare records, as summarized in Figure 3. This expansion highlights the Transformer’s versatile capacity for temporal data analysis.\\n# Foundation Models for Time Series Analysis: A Tutorial and Survey\\n\\n# KDD ’24, August 25–29, 2024, Barcelona, Spain\\n\\n# 5.1.2 Non-Transformer-based Models\\n\\nExcluding the widespread adoption of Transformers, a diverse array of traditional pre-training methods leveraged models such as Multi-Layer Perceptrons (MLPs) [31], Recurrent Neural Networks (RNNs) [33], and Convolutional Neural Networks (CNNs) [98] as the backbone for pre-training. These models, each with their unique strengths, are notable for their effectiveness in both conventional and spatial time series data.\\n\\nalso unable to model long-term trends effectively [4, 14, 62]. This is because, at each timestamp, a recurrent model needs to first perform inference for all previous timestamps before proceeding further. Recent developments of the transformer models allow single-shot inference with the complete input series using position encoding [51]. Using transformers allows much faster detection compared to recurrent methods by parallelizing inference on GPUs [19]. However, transformers also provide the benefit of being able to encode large sequences with accuracy and training/inference times nearly agnostic to the sequence length [51]. Thus, we use transformers to grow the temporal context information sent to an anomaly detector without significantly increasing the computational overheads.\\n\\n# Our contributions\\n\\n# Trend and seasonality.\\n\\nWe generated time series following linear and exponential trends: Chronos-T5 (Base) predicts the linear trend accurately but struggles with the exponential trend, as shown in Figure 12b. This may be due to a limited representation of exponential trends in the training data. A potential resolution for generating better forecasts for time series with exponential trends is to perform logarithmic scaling before feeding the time series.\\n\\n16\\n# Forecasting with Chronos Models\\n\\nQuestion:\\nWhat are the main trade-offs when choosing between transformer-based models and traditional time-series models?\\n\\nAnswer:\\n', 'model': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'temperature': 0.0, 'max_tokens': 500, 'repetition_penalty': 1.2, 'stop': [\"I don't know.\"]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What are the main trade-offs when choosing between transformer-based models and traditional time-series models?\n",
       "\n",
       "**Risposta:** When deciding between transformer-based models and traditional time-series models like MLPs, RNNs, or CNNs, there are several key considerations:\n",
       "\n",
       "*   **Computational Resources:** Traditional models can require significant computational resources and time for inference, especially when dealing with complex tasks or large datasets. In contrast, recent advancements have enabled transformer-based models to achieve fast single-shot inference with minimal additional computational costs.\n",
       "*   **Temporal Context Modeling:** While traditional models excel in modeling short-term dependencies within time series, they often struggle with capturing longer-term patterns and trends. On the other hand, transformer-based models offer improved performance in this regard, thanks to their ability to process entire input sequences simultaneously through positional encodings.\n",
       "*   **Training/Inference Times:** The choice between these two types of models depends heavily on whether you prioritize speed during training and inference phases. Traditional models tend to take more time to train and infer upon larger inputs, whereas transformer-based architectures exhibit near-linear scalability regarding sequence lengths, making them suitable choices where rapid processing is essential.\n",
       "*   **Representation Learning:** Another crucial aspect is the type of representations learned by different models. Traditional models typically rely on fixed-size feature vectors extracted from local neighborhoods around each point in space-time, which might limit their ability to capture global structures inherent in many natural phenomena. Conversely, transformer-based models learn contextualized embeddings directly from raw sequential data points, allowing them to represent higher-order relationships among elements within those sequences efficiently.\n",
       "\n",
       "\n",
       "\n",
       "These factors highlight some fundamental differences between transformer-based models and traditional time-series models, influencing decisions about which approach best suits specific applications' requirements. By understanding these trade-offs, researchers and practitioners can make informed selections tailored to their particular goals and constraints. I hope it helps! Let me know if you need anything else."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await ask_question_naive(query_global3)\n",
    "\n",
    "end_time = time.time()\n",
    "time_global_naive3 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.2.4 Quarta query globale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GraphRAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Domanda:** How do anomaly detection models like AnomalyBERT, TranAD, and RestAD compare in terms of their robustness and adaptability to various types of anomalies (contextual, point, collective) across different time series domains?\n",
       "\n",
       "**Risposta:**\n",
       "# Anomaly Detection Models Comparison\n",
       "=====================================\n",
       "\n",
       "## Robustness and Adaptability of Anomaly Detection Models\n",
       "--------------------------------------------------------\n",
       "\n",
       "Anomaly detection models like AnomalyBERT, TranAD, and RestAD have been evaluated for their robustness and adaptability to various types of anomalies (contextual, point, collective) across different time series domains.\n",
       "\n",
       "### Key Findings\n",
       "---------------\n",
       "\n",
       "*   **TranAD** is a robust and adaptable model for detecting anomalies in multivariate time series data, including contextual, point, and collective anomalies, across different time series domains [Data: Reports (34, 75, 335, 269, 157, +more)].\n",
       "*   **AnomalyBERT** is a robust model for detecting contextual anomalies in time series data, but its performance may degrade in the presence of point or collective anomalies [Data: Reports (258, 284, 283)].\n",
       "*   **RestAD** is a robust model for detecting collective anomalies in time series data, but its performance may degrade in the presence of contextual or point anomalies [Data: Reports (136, 170, 360)].\n",
       "\n",
       "### Comparison of Models\n",
       "-------------------------\n",
       "\n",
       "Comparative studies have shown that AnomalyBERT, TranAD, and RestAD have varying levels of robustness and adaptability to different types of anomalies and time series domains [Data: Reports (75, 335, 269, 157, 87, +more)].\n",
       "\n",
       "### Factors Influencing Performance\n",
       "-----------------------------------\n",
       "\n",
       "The performance of AnomalyBERT, TranAD, and RestAD may be influenced by factors such as data quality, feature engineering, and hyperparameter tuning [Data: Reports (273, 218, 386)].\n",
       "\n",
       "### Future Research Directions\n",
       "-------------------------------\n",
       "\n",
       "Further research is needed to fully understand the strengths and limitations of these models in different time series domains and to develop more robust and adaptable anomaly detection methods [Data: Reports (321, 187, 44)].\n",
       "\n",
       "### Techniques for Improving Robustness and Adaptability\n",
       "--------------------------------------------------------\n",
       "\n",
       "The robustness and adaptability of AnomalyBERT, TranAD, and RestAD models can be improved by using techniques such as data augmentation, transfer learning, and ensemble methods [Data: Reports (210, 346, 328)].\n",
       "\n",
       "### Conclusion\n",
       "----------\n",
       "\n",
       "In conclusion, while AnomalyBERT, TranAD, and RestAD have shown promising results in detecting anomalies in time series data, their robustness and adaptability to various types of anomalies and domains vary. Further research is needed to fully understand their strengths and limitations and to develop more robust and adaptable anomaly detection methods."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await test_global_graph(query_global4)\n",
    "\n",
    "end_time = time.time()\n",
    "time_global_graph4 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG tradizionale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload inviato all'API: {'prompt': '\\nYou are a knowledgeable assistant specialized in answering questions based solely on the provided context. Provide a detailed and well-structured answer, including all relevant information from the context. Ensure your response is comprehensive, faithful to the context, and presented in clear, well-formed sentences. Do not add any information that is not present in the context. If the answer is not explicitly stated in the context, respond with \"I don\\'t know.\"\\n\\nContext:\\n# 4 Experiments\\n\\nWe compare TranAD with state-of-the-art models for multivariate time-series anomaly detection, including MERLIN, LSTM-NDT (with autoencoder implementation from openGauss), DAGMM, OmniAnomaly, MSCRED, MAD-GAN, USAD, MTAD-GAT, CAE-M and GDN (with graph embedding implementation from GraphAn). For more details refer Section 2.1. We also tested the Isolation Forest method, but due to its low F1 scores, do not include the corresponding results in our discussion. Other classical methods have been omitted as well.\\n\\nThe recently proposed HitAnomaly [19] method uses vanilla transformers as encoder-decoder networks, but is only applicable to natural-language log data and not appropriate for generic continuous time-series data as inputs. In our experiments, we compare TranAD against the state-of-the-art methods MERLIN, LSTM-NDT, DAGMM, OmniAnomaly, MSCRED, MAD-GAN, USAD, MTAD-GAT, CAE-M and GDN. These methods have shown superiority in anomaly detection and diagnosis, but complement one another in terms of performance across different time-series datasets. Out of these, only USAD aims to reduce training times, but does this to a limited extent. Just like reconstruction based prior work [4, 29, 45, 60, 61], we develop a TranAD model that learns broad level trends using training data to find anomalies in test data. We specifically improve anomaly detection and diagnosis performance with also reducing the training times in this work.\\n\\n# 3 Methodology\\n\\n# 3.1 Problem Formulation\\n\\n# RESTAD: REconstruction and Similarity based Transformer for time series Anomaly Detection\\n\\nPreprint\\n\\nRamin Ghorbani1∗, Marcel J.T. Reinders1, and David M.J. Tax1\\n\\n1Pattern Recognition Lab, Delft University of Technology, Delft, Netherlands\\n\\n# Abstract\\n\\n# Evaluation\\n\\nAnomaly scores (Eq. 2) exceeding a threshold δ are identified as anomalies. Performance is evaluated using the F1-score for threshold-dependent evaluation. Here, we follow [17] by setting δ to label a predefined proportion of data points as anomalies (0.5% for SMD, 1% for others). For threshold-independent analysis, we use AUC-ROC, AUC-PR, VUS-ROC, and VUS-PR metrics [21]. We exclude the point-adjustment method [22] due to its overestimation [23]. Our model is compared against baselines and state-of-the-arts models: LSTM [9], vanilla Transformer [17], USAD [13], PatchAD [12], AnomalyTrans [17], and DCdetector [10].\\n\\n1 https://github.com/Raminghorbanii/RESTAD\\n# RESTAD: REconstruction and Similarity based Transformer for time series Anomaly Detection\\n\\n# Table 1: Performance metrics of baselines and RESTAD on test sets.\\n\\nInitialization methods are denoted as (R) for Random and (K) for K-means. For all measures, a higher value indicates better anomaly detection performance.\\n\\nOur task is to determine if a given xi,t shows any anomalous behavior or not.\\n# RESTAD: REconstruction and Similarity based Transformer for time series Anomaly Detection\\n\\n# Data\\n\\n|Input|Embedding|Encoder Layer 1|Encoder Layer 2|RBF Layer|Encoder Layer 3|Fully Connected Layer|Output Layer|\\n|---|---|---|---|---|---|---|---|\\n|Multi-Head Attention (8x)|Dropout|+|Norm|Feed-Forward|Norm|+| |\\n\\nFigure 2: Overview of the proposed RESTAD model. Here, the RBF layer is added after the second encoder layer.\\n\\n# Model Score\\n\\nRESTAD score(xi,t) = ϵr × ϵs (2)\\n\\nand ϵs = ||xi,t PM=1 ||2 represents the reconstruction error, where ϵr = 1 − M1 − ˆi,tzm,t measures dissimilarity. This combination highlights subtle anomalies characterized by both low reconstruction errors and RBF scores, as well as significant anomalies with high reconstruction errors or low RBF scores.\\n\\n# Initialization of RBF Layer Parameters\\n\\nQuestion:\\nHow do anomaly detection models like AnomalyBERT, TranAD, and RestAD compare in terms of their robustness and adaptability to various types of anomalies (contextual, point, collective) across different time series domains?\\n\\nAnswer:\\n', 'model': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'temperature': 0.0, 'max_tokens': 500, 'repetition_penalty': 1.2, 'stop': [\"I don't know.\"]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** How do anomaly detection models like AnomalyBERT, TranAD, and RestAD compare in terms of their robustness and adaptability to various types of anomalies (contextual, point, collective) across different time series domains?\n",
       "\n",
       "**Risposta:** Unfortunately, there's no direct comparison between AnomalyBERT, TranAD, and RestAD regarding their robustness and adaptability to contextual, point, and collective anomalies across diverse time series domains within the provided text. The passage discusses TranAD's advantages over other state-of-the-art models such as MERLIN, LSTM-NDT, DAGMM, etc., focusing primarily on its ability to detect anomalies while reducing training times. However, it doesn't provide specific insights into how these three models perform relative to each other concerning robustness and adaptability to different types of anomalies. Therefore, I cannot offer an accurate assessment without additional context or comparative studies involving these models. \n",
       "\n",
       "However, according to the abstract section, the authors mention that they aim to improve anomaly detection and diagnosis performance along with reducing training times, which might imply some degree of adaptability and robustness. Nonetheless, explicit comparisons among AnomalyBERT, TranAD, and RestAD remain absent from the provided text. Hence, further research would be necessary to accurately assess their respective strengths and weaknesses in handling various types of anomalies across multiple time series domains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await ask_question_naive(query_global4)\n",
    "\n",
    "end_time = time.time()\n",
    "time_global_naive4 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.2.5 Quinta query globale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GraphRAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Domanda:** How does TimeGPT approach time-series forecasting?\n",
       "\n",
       "**Risposta:**\n",
       "**TimeGPT Approach to Time-Series Forecasting**\n",
       "=====================================================\n",
       "\n",
       "TimeGPT is a pre-trained foundation model specifically designed for time series forecasting. It utilizes a combination of techniques, including attention mechanisms and diffusion models, to capture complex patterns and relationships in time series data.\n",
       "\n",
       "**Key Features of TimeGPT**\n",
       "---------------------------\n",
       "\n",
       "*   **Transformer-based Architecture**: TimeGPT employs a transformer-based architecture, which allows it to capture long-term dependencies and patterns in the data.\n",
       "*   **Attention Mechanisms**: TimeGPT utilizes attention mechanisms to focus on specific parts of the input data that are relevant to the forecasting task.\n",
       "*   **Diffusion Models**: TimeGPT incorporates diffusion models to capture complex patterns and relationships in the data.\n",
       "*   **Fine-tuning**: TimeGPT can be fine-tuned for specific time series forecasting tasks, allowing it to adapt to different datasets and problem domains.\n",
       "\n",
       "**Performance of TimeGPT**\n",
       "-------------------------\n",
       "\n",
       "TimeGPT has been shown to outperform other models in various time series forecasting tasks, including short-term and long-term forecasting. Its performance is attributed to its ability to capture both local and global patterns in the data.\n",
       "\n",
       "**Applications of TimeGPT**\n",
       "---------------------------\n",
       "\n",
       "TimeGPT has been applied to a variety of real-world datasets and has demonstrated its potential for practical use in time-series forecasting. Its ability to handle large datasets and complex patterns makes it a suitable choice for domains such as energy forecasting, finance, and climate modeling.\n",
       "\n",
       "**Data References**\n",
       "-------------------\n",
       "\n",
       "*   [Data: Reports (264, 67, 288, 308, 273)] - TimeGPT's pre-trained foundation model specifically designed for time series forecasting.\n",
       "*   [Data: Reports (273, 67, 288, 308)] - TimeGPT's performance in various time series forecasting tasks.\n",
       "*   [Data: Reports (22, 231, 265, +more)] - TimeGPT's transformer-based architecture and fine-tuning capabilities.\n",
       "*   [Data: Reports (245, 308, 288)] - TimeGPT's fine-tuning for specific time series forecasting tasks.\n",
       "*   [Data: Reports (181, 202, 355, 286, 289, +more)] - TimeGPT's association with entities such as 2-layer MLPs and residual connections.\n",
       "\n",
       "Note: The data references provided are a selection of the most relevant reports from the analysts' reports. There may be additional reports that provide further information on TimeGPT's approach to time-series forecasting."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await test_global_graph(query_global5)\n",
    "\n",
    "end_time = time.time()\n",
    "time_global_graph5 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG tradizionale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload inviato all'API: {'prompt': '\\nYou are a knowledgeable assistant specialized in answering questions based solely on the provided context. Provide a detailed and well-structured answer, including all relevant information from the context. Ensure your response is comprehensive, faithful to the context, and presented in clear, well-formed sentences. Do not add any information that is not present in the context. If the answer is not explicitly stated in the context, respond with \"I don\\'t know.\"\\n\\nContext:\\n# 5 TimeGPT\\n\\n# 5.1 Architecture\\n\\nTimeGPT is a Transformer-based time series model with self-attention mechanisms based on [Vaswani et al., 2017]. TimeGPT takes a window of historical values to produce the forecast, adding local positional encoding to enrich the input. The architecture consists of an encoder-decoder structure with multiple layers, each with residual connections and layer normalization. Finally, a linear layer maps the decoder’s output to the forecasting window dimension. The general intuition is that attention-based mechanisms are able to capture the diversity of past events and correctly extrapolate potential future distributions.\\n\\nThe evaluation is performed in the last forecasting window of each time series, varying in length by the sampling frequency. TimeGPT uses the previous historical values as inputs, as shown in Figure 3, without re-training its weights (zero-shot). We specify a different forecasting horizon based on the frequency to represent common practical applications: 12 for monthly, 1 for weekly, 7 for daily, and 24 for hourly data. 4\\n\\nFurthermore, adjacent questions about foundation models for time series classification and the integration of truly multimodal (text, video) and multi-temporal foundation models promise to be engaging areas for future study. These areas will not only extend our understanding of time series data but also improve our ability to develop more powerful and generalized models for forecasting.\\n\\n# Access and early testing\\n\\nTimeGPT has undergone rigorous internal testing, demonstrating robust performance across various domains and frequencies. As we move forward, we invite practitioners and researchers to explore its capabilities on their own datasets and tasks.\\n\\nTo facilitate this, we have released comprehensive guides that explain how to utilize TimeGPT with features including uncertainty quantification, fine-tuning, forecasting multiple time series, integrating calendar and exogenous variables, and performing anomaly detection.\\n\\nIn this paper, we embark on a novel path and introduce TimeGPT, the first pre-trained foundation model for time series forecasting that can produce accurate predictions across a diverse array of domains and applications without additional training. A general pre-trained model constitutes a\\n\\n∗Authors contributed equally.\\n# Groundbreaking Innovation\\n\\nGroundbreaking innovation that opens the path to a new paradigm for the forecasting practice that is more accessible and accurate, less time-consuming, and drastically reduces computational complexity.\\n\\n# 2 Background\\n\\n# Multi-Head Attention\\n\\n# Inference\\n\\n# Retail\\n\\n# Tourism\\n\\n# IoT\\n\\n# Positional Encoding\\n\\n# Input Embedding\\n\\n# Output Embedding\\n\\n# Inputs (shifted right)\\n\\n# Healthcare\\n\\n# Transport\\n\\n# Economics\\n\\nFigure 2: TimeGPT was trained in the largest collection of publicly available time series, and can forecast unseen time series without re-training its parameters.\\n\\nA forecasting model provides a function fθ : X  ↦ Y, with X the feature space and Y the dependent variable space. We consider the setting with X = {y[0:t], x[0:t+h]} and Y = {y[t+1:t+h]}, where h is the forecast horizon, y is the target time series, and x are exogenous covariates. The forecasting task objective is to estimate the following conditional distribution:\\n\\nP(y[t+1:t+h]| y[0:t], x[0:t+h]) = fθ(y[0:t], x[0:t+h]) (1)\\n\\nQuestion:\\nHow does TimeGPT approach time-series forecasting?\\n\\nAnswer:\\n', 'model': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'temperature': 0.0, 'max_tokens': 500, 'repetition_penalty': 1.2, 'stop': [\"I don't know.\"]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** How does TimeGPT approach time-series forecasting?\n",
       "\n",
       "**Risposta:** According to the given context, TimeGPT approaches time-series forecasting using a Transformer-based architecture with self-attention mechanisms inspired by Vaswani et al.'s work [2017]. It utilizes a combination of an encoder-decoder structure with multiple layers, incorporating residual connections and layer normalization. Additionally, it employs local positional encoding to enhance the input. Furthermore, TimeGPT produces forecasts directly from the previously observed historical values without requiring retraining or adjusting its weights (\"zero-shot\"). This allows it to generate accurate predictions across various domains and frequencies without extensive computation or manual intervention. I do not know if there's anything else beyond what's mentioned here regarding TimeGPT's specific methodology for approaching time-series forecasting. However, the text highlights several key aspects such as utilizing prior knowledge through zero-shot learning, leveraging transformer architectures effectively, and focusing on capturing temporal relationships within sequences via self-attentive mechanisms. \n",
       "\n",
       "Note: There might be some minor errors due to formatting issues while copying the content into the question box. Please let me correct them before providing feedback! Thank you so much again for pointing out these mistakes. Have a great day ahead!! \n",
       "Please feel free to ask follow-up questions or request further clarification if needed. I'll make sure my responses remain grounded in the original context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await ask_question_naive(query_global5)\n",
    "\n",
    "end_time = time.time()\n",
    "time_global_naive5 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Confronto dei tempi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_global = {\n",
    "    'Domanda': [1, 2, 3, 4, 5],\n",
    "    'Time Naive': [time_global_naive1, time_global_naive2, time_global_naive3, time_global_naive4, time_global_naive5],\n",
    "    'Time GraphRAG': [time_global_graph1, time_global_graph2, time_global_graph3, time_global_graph4, time_global_graph5]\n",
    "}\n",
    "\n",
    "df_global = pd.DataFrame(data_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Domanda  Time Naive  Time GraphRAG\n",
      "0        1   10.697026      21.665362\n",
      "1        2    7.139635      25.449770\n",
      "2        3    7.620632      20.155527\n",
      "3        4    4.787009      21.762643\n",
      "4        5    5.555050      23.262753\n"
     ]
    }
   ],
   "source": [
    "print(df_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_global_naive = df_global['Time Naive'].mean()\n",
    "mean_global_graph = df_global['Time GraphRAG'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo medio Naive: 7.16 secondi\n",
      "Tempo medio GraphRAG: 22.46 secondi\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tempo medio Naive: {mean_global_naive:.2f} secondi\")\n",
    "print(f\"Tempo medio GraphRAG: {mean_global_graph:.2f} secondi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_global.plot(x='Domanda', y=['Time Naive', 'Time GraphRAG'], kind='bar', figsize=(10, 6))\n",
    "plt.title('Confronto Tempi Naive vs GraphRAG per Domanda')\n",
    "plt.ylabel('Tempo (secondi)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAF2CAYAAADUchpQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+XElEQVR4nO3dd1hUV/4G8HdoQx+kKhFpVlBsGKKo2Ci2FctGERWCbRM7URNsgCbWFXtZjTHGrtHo7hp7bDFEYyyxxYKoGKOgCAgSLJzfH1nm5ziAM9wZGeT9PM88j3PumXu/d5yZ+3JukwkhBIiIiIjKyKi8CyAiIqKKjWGCiIiIJGGYICIiIkkYJoiIiEgShgkiIiKShGGCiIiIJGGYICIiIkkYJoiIiEgShgkiIiKShGGCdOLatWsICQmBQqGATCbDjh07yrukSksmkyEhIaG8yyhRdHQ0PDw8VNoMteY2bdqgTZs25V1GpRMdHQ1ra+vyLoO0wDDxFklJScHQoUPh5eUFc3Nz2NraIjAwEAsWLEB+fr5elx0VFYXz58/j888/x9q1a+Hv76/X5b3q0qVLSEhIwM2bN3U2T5lMptHj8OHDOlvmm3Lz5k1l/Z999lmxfSIjIyGTyQz+R/2rr76CTCaDubk5fv/9d7Xpbdq0Qf369cuhMsNWWFiIr7/+GsHBwXB0dISpqSmcnZ0REhKCFStWoKCgoLxL1Mir30dbW1sEBQVh165dJb4mKysL5ubmkMlkuHz5con93pb36E0wKe8CSDd27dqFv//975DL5RgwYADq16+Pp0+f4ocffsC4ceNw8eJFrFixQi/Lzs/PR3JyMiZOnIjhw4frZRmvc+nSJSQmJqJNmzZqf/WW1dq1a1Wef/3119i/f79ae7169XSyPF3Jz8+HiYlmX21zc3Ns3LgRkyZNUmnPy8vDzp07YW5uro8S1WhTc0kKCgowc+ZMLFq0SEdVAfv27dPZvAxJfn4+unfvjr1796JFixYYO3YsXFxckJmZiSNHjuCjjz7CiRMnsGrVqvIuVSPBwcEYMGAAhBC4desWli1bhq5du2L37t0IDQ1V679161bIZDJUrVoV69evLzZQv23vkd4JqvBu3LghrK2tRd26dcXdu3fVpl+7dk3Mnz9fb8u/deuWACDmzJnz2r65ubl6qWHr1q0CgDh06JBe5i+EEMOGDRNvy1cmNTVVABA9evQQAMTZs2dVpq9fv16YmpqKrl27CisrK50uOyoqSri7u+tsfqtXrxYARKNGjYRcLhe///67yvSgoCDh6+urs+W9DYYOHSoAlPi7cPXqVbFkyZJS5/Hs2TNRUFCgj/JEVFSUxp87AGLYsGEqbZcuXRIARMeOHYt9TevWrUWPHj3EmDFjhKenZ7F9dPEeVSZvxy9jJfePf/xDABDHjx/XqP+zZ8/E1KlThZeXlzAzMxPu7u4iLi5O/Pnnnyr93N3dRefOncWxY8dEs2bNhFwuF56enmLNmjXKPvHx8QKAyqNoQ1E07eLFiyIiIkLY2dmJRo0a6byGoo3Jq4+Xg8WSJUuEj4+PMDMzE9WqVRMfffSRePTokRbvcvFh4sWLF2LevHnCx8dHyOVy4ezsLIYMGSIyMzOLXY9Dhw6Jpk2bCnNzc1G/fn1ljdu2bRP169cXcrlcNGnSRJw+fVrl9UU/rikpKSIkJERYWlqKatWqicTERFFYWKjSF4CIj48vdV2KwsScOXOEp6enGD9+vMr0Tp06ia5du5b4o/7dd9+Jli1bCktLS2FtbS06deokLly4oNbv22+/Fb6+vkIulwtfX1+xffv2YsNEcTVfvnxZ3Lp1q9T1EOL///+3bNkiTExMxIgRI1SmFxcmvvzyS9G2bVvh5OQkzMzMRL169cTSpUvV5h0UFCSCgoKEEELcu3dPGBsbi4SEBLV+v/32mwAgFi1apGx79OiRGDVqlKhevbowMzMT3t7eYubMmeLFixelrk/nzp1L3MC99957omnTpsrn+/btE4GBgUKhUAgrKytRu3ZtERcXV+r8b9++LYyNjUVYWFip/V728udl3rx5wsvLSxgZGYkzZ86IgoICMXnyZNGkSRNha2srLC0tRcuWLcX3339f4jySkpJEjRo1hLm5uWjdurU4f/68St+iz92dO3dEt27dhJWVlXB0dBQff/yxeP78uUrf4sKEEEI4OjqK2rVrq7XfunVLyGQysWXLFnHixIlifzvL8h5VdgwTb4F33nlHeHl5adw/KipKABC9evUSS5YsEQMGDBAARHh4uEo/d3d3UadOHeHi4iImTJggFi9eLJo0aSJkMplyw3Hu3Dkxb948AUBERESItWvXim+//VYI8f9hwsfHR3Tr1k0sXbpUmeR1WUNKSooYOXKkACAmTJgg1q5dK9auXSvu3bunUkeHDh3EokWLxPDhw4WxsbFo1qyZePr0qcbvW3FhYtCgQcLExEQMHjxYLF++XHzyySfCyspKbd5F61GtWjWRkJAg5s2bJ9555x1hbW0t1q1bJ2rUqCFmzpwpZs6cKRQKhahZs6bKRicqKkqYm5uLWrVqif79+4vFixeLLl26CABi8uTJKjVpGyYmTJggatSooQwlGRkZwsTERGzcuLHYMPH1118LmUwmwsLCxKJFi8SsWbOEh4eHsLOzE6mpqcp+e/fuFUZGRqJ+/foiKSlJTJw4USgUCuHr66tRmACg3JCXpihM/PzzzyImJkaYm5urjE4UFyaaNWsmoqOjxbx588SiRYtESEiIACAWL16s0u/lMCGEEO3atRM+Pj5qNSQmJgpjY2PlZy4vL0/4+fkJBwcHMWHCBLF8+XIxYMAAIZPJxKhRo0pdn6+//loAECdPnlRpv3nzpsoI4IULF4SZmZnw9/cXCxYsEMuXLxdjx44VrVu3LnX+//rXvwQAsW7dulL7vazo8+Lj4yO8vLzEzJkzxbx588StW7dERkaGqFatmoiNjRXLli0Ts2fPFnXq1BGmpqbizJkzavNo0KCB8PDwELNmzRKJiYnC3t5eODk5Kd87If7/8+7r6ytiYmLEsmXLRM+ePQUAtdBXXJjIysoSxsbGIiAgQG1dZs6cKaytrcWTJ0+EEEJ4e3uLjz76SPJ7VNkxTFRw2dnZAoDo1q2bRv3Pnj0rAIhBgwaptI8dO1YAUPlrwt3dXQAQR48eVbalp6cLuVwuPv74Y2XbyxumlxVtxCMiIvReQ0m7OdLT04WZmZkICQlR2TgvXrxYABBffvllie/Vq14NE8eOHRMAxPr161X67dmzR629aD1+/PFHZdvevXsFAGFhYaHyF3jRD9nL61IUvl7+q7uwsFB07txZmJmZiYyMDGW7tmHiwoULAoA4duyYEOKvURxra2uRl5enFiYeP34s7OzsxODBg1Xmd+/ePaFQKFTaGzVqJKpVqyaysrKUbfv27VMZvSqt5rKEiZSUFGFiYiJGjhypnF5cmCjakLwsNDRULZS/GiaK/m9e/Uvax8dHtGvXTvl82rRpwsrKSly9elWl36effiqMjY3F7du3S1yf7Oxstc+3EELMnj1byGQy5WelKMS//H+viTFjxhS7a6ugoEBkZGQoHw8ePFBOK/q82NraivT0dJXXPX/+XG13x6NHj4SLi4uIiYlRm4eFhYW4c+eOsr1odGDMmDHKtqLP+9SpU1Xm27hxY5WRGSH++pwMHDhQZGRkiPT0dHHq1CkRFhZW4q7XBg0aiMjISOXzCRMmCEdHR/Hs2TNJ71Flx7M5KricnBwAgI2NjUb9v/vuOwBAbGysSvvHH38MAGpHQPv4+KBVq1bK505OTqhTpw5u3LihcY3/+Mc/yq2GAwcO4OnTpxg9ejSMjP7/4z548GDY2tqWesT362zduhUKhQLBwcF48OCB8tG0aVNYW1vj0KFDauvRvHlz5fOAgAAAQLt27VCjRg219uLW7+UDXGUyGYYPH46nT5/iwIEDZV4PX19f+Pn5YePGjQCADRs2oFu3brC0tFTru3//fmRlZSEiIkJlnY2NjREQEKBc5z/++ANnz55FVFQUFAqF8vXBwcHw8fHRqC4hhNZnynh5eaF///5YsWIF/vjjjxL7WVhYKP+dnZ2NBw8eICgoCDdu3EB2dnaJr+vRowdMTEywefNmZduFCxdw6dIl9O7dW9m2detWtGrVClWqVFF5nzp06IAXL17g6NGjJS7D1tYWHTt2xJYtWyCEULZv3rwZ7733nvKzYmdnBwDYuXMnCgsLS35TXlH0m/HqWTrfffcdnJyclA93d3e11/bs2RNOTk4qbcbGxjAzMwPw19kPmZmZeP78Ofz9/XH69Gm1eYSHh+Odd95RPn/33XcREBCg/F142au/Ha1atSr2e7Fq1So4OTnB2dkZ/v7+OHjwIMaPH6/2G/Prr7/i/PnziIiIULYVfZb37t2rbJPyHlVWDBMVnK2tLQDg8ePHGvW/desWjIyMULNmTZX2qlWrws7ODrdu3VJpf3kjV6RKlSp49OiRxjV6enqWWw1F86pTp45Ku5mZGby8vNSWpY1r164hOzsbzs7OKj8wTk5OyM3NRXp6eqnrUbSRdXNzK7b91fUzMjKCl5eXSlvt2rUBQPIpsX379sXWrVtx/fp1/Pjjj+jbt2+x/a5duwbgrwD06jrv27dPuc5F72utWrXU5vHq/4WuTZo0Cc+fP8fMmTNL7HP8+HF06NABVlZWsLOzg5OTEyZMmAAApYYJR0dHtG/fHlu2bFG2bd68GSYmJujRo4ey7dq1a9izZ4/ae9ShQwcAUPtsvKp3795IS0tDcnIygL9O+/7ll19UAkvv3r0RGBiIQYMGwcXFBX369MGWLVteGyyK/vDIzc1VaQ8MDMT+/fuxf/9+hISEFPvaV7/LRdasWQM/Pz+Ym5vDwcEBTk5O2LVrV7HvZXGfidq1a6t9hs3NzdWCS0nf+27dumH//v3YtWsXEhISIJPJ8OTJE5U/IABg3bp1sLKygpeXF65fv47r16/D3NwcHh4eWL9+vbKflPeosuKpoRWcra0tXF1dceHCBa1eJ5PJNOpnbGxcbPvLfzG9zst/BZZXDfpQWFgIZ2dnlR+hlxX3F1xxDGH9IiIiEBcXh8GDB8PBwaHEH8qiDdXatWtRtWpVtelST+/UBS8vL/Tr1w8rVqzAp59+qjY9JSUF7du3R926dZGUlAQ3NzeYmZnhu+++w7x58167Me7Tpw8++OADnD17Fo0aNcKWLVvQvn17ODo6KvsUFhYiODgY48ePL3YeRSGwJF27doWlpSW2bNmCFi1aYMuWLTAyMsLf//53ZR8LCwscPXoUhw4dwq5du7Bnzx5s3rwZ7dq1w759+0r8XNWtWxfAXyMqDRs2VLa/HHbWrVtX7GuL+y6vW7cO0dHRCA8Px7hx4+Ds7AxjY2PMmDEDKSkppa5naUqqvzjVq1dX1t6pUyc4Ojpi+PDhaNu2rTLkCSGwceNG5OXlFTs6lp6ejtzcXFhbW0t6jyqr8v/mk2RdunTBihUrkJycrDKMXhx3d3cUFhbi2rVrKtdHuH//PrKyst7IsJ0+aigpmBTN68qVKyp/1T99+hSpqanKH4ay8Pb2xoEDBxAYGFhiYNKlwsJC3LhxQ2VDdPXqVQCQfG2NGjVqIDAwEIcPH8aHH35YYijw9vYGADg7O5f63hW970UjGS+7cuWKpFo1MWnSJKxbtw6zZs1Sm/af//wHBQUF+Pe//60yWvTqbqmShIeHY+jQocpdHVevXkVcXJxKH29vb+Tm5pb582VlZYUuXbpg69atSEpKwubNm9GqVSu4urqq9DMyMkL79u3Rvn17JCUlYfr06Zg4cSIOHTpU4rI7duwIY2NjrF+/HpGRkWWq72XffPMNvLy8sH37dpXvYXx8fLH9i/tMXL16VWfXhwGAoUOHYt68eZg0aRK6d+8OmUyGI0eO4M6dO5g6daratWEePXqEIUOGYMeOHejXr5/O36PKgLs53gLjx4+HlZUVBg0ahPv376tNT0lJwYIFCwD8ldoBYP78+Sp9kpKSAACdO3fWb7F6qsHKygrAX1e2e1mHDh1gZmaGhQsXqvylv2rVKmRnZ0ta3/fffx8vXrzAtGnT1KY9f/5crRZdWLx4sfLfQggsXrwYpqamaN++veR5f/bZZ4iPj8eIESNK7BMaGgpbW1tMnz4dz549U5uekZEBAKhWrRoaNWqENWvWqAx179+/H5cuXdKont9++w23b9/Wci3+4u3tjX79+uFf//oX7t27pzKt6C/elz8P2dnZWL16tUbztrOzQ2hoKLZs2YJNmzbBzMwM4eHhKn3ef/99JCcnq+yHL5KVlYXnz5+/djm9e/fG3bt38cUXX+DcuXMquzgAIDMzU+01jRo1AoBSr8xYo0YNxMTEYPfu3Sqfp5dpMypW3Pt54sQJ5S6aV+3YsUPlSqUnT57EiRMn0LFjR42X+TomJib4+OOPcfnyZezcuRPA/+/iGDduHHr16qXyGDx4MGrVqqUcZdT1e1QZcGTiLeDt7Y0NGzagd+/eqFevnsoVMH/88Uds3boV0dHRAICGDRsiKioKK1asQFZWFoKCgnDy5EmsWbMG4eHhaNu2rd7r1UcNjRo1grGxMWbNmoXs7GzI5XK0a9cOzs7OiIuLQ2JiIsLCwvC3v/0NV65cwdKlS9GsWTP069evzOsRFBSEoUOHYsaMGTh79ixCQkJgamqKa9euYevWrViwYAF69epV5vm/ytzcHHv27EFUVBQCAgKwe/du7Nq1CxMmTFDbpVIWQUFBCAoKKrWPra0tli1bhv79+6NJkybo06cPnJyccPv2bezatQuBgYHKH98ZM2agc+fOaNmyJWJiYpCZmYlFixbB19dXbV90cerVq4egoKAyX6584sSJWLt2La5cuQJfX19le0hICMzMzNC1a1cMHToUubm5WLlyJZydnUs9aPNlvXv3Rr9+/bB06VKEhoYqD4YsMm7cOPz73/9Gly5dEB0djaZNmyIvLw/nz5/HN998g5s3b6rsFilOp06dYGNjg7Fjx8LY2Bg9e/ZUmT516lQcPXoUnTt3hru7O9LT07F06VJUr14dLVu2LHXe8+fPR2pqKkaMGIFNmzaha9eucHZ2xoMHD3D8+HH85z//0fjYli5dumD79u3o3r07OnfujNTUVCxfvhw+Pj7F/j/XrFkTLVu2xIcffoiCggLMnz8fDg4OJe4SKqvo6GhMmTIFs2bNQseOHbFt2zYEBweXeFXXv/3tb1iwYAHS09Ph7Oys0/eoUiifk0hIH65evSoGDx4sPDw8hJmZmbCxsRGBgYFi0aJFKheDevbsmUhMTBSenp7C1NRUuLm5lXrBqFe9errc604NLe7UNV3XIIQQK1euFF5eXsLY2Fjt1MrFixeLunXrClNTU+Hi4iI+/PBDnVy0SgghVqxYIZo2bSosLCyEjY2NaNCggRg/frzK1UhLWg8Uc458ce9ncRetcnFxEfHx8WoXQYKWp4aWpqSLVh06dEiEhoYKhUIhzM3Nhbe3t4iOjhanTp1S6bdt2zZRr149IZfLhY+Pj1YXrUIZTg0trn4AaqeG/vvf/xZ+fn7C3Nxcec2DL7/8UgBQuVZGcZ8zIYTIyckRFhYWpV6L4PHjxyIuLk7UrFlTmJmZCUdHR9GiRQvxz3/+U+Prm0RGRiqvkfKqgwcPim7duglXV1dhZmYmXF1dRUREhNrpqCV5/vy5WL16tWjXrp2wt7cXJiYmwtHRUbRv314sX75c5OfnK/uW9nkpLCwU06dPF+7u7kIul4vGjRuL//73v2r/zy/PY+7cucLNzU3I5XLRqlUrce7cOZV5lvS5K/pNeVlx36EiCQkJAoDYtm2bACBWrVpV4vtx+PBhAUAsWLCgTO9RZScTgmM1RIYuOjoa33zzjUZ/0RMZops3b8LT0xNz5szB2LFjy7sc0jEeM0FERESSMEwQERGRJAwTREREJAmPmSAiIiJJODJBREREkjBMEBERkSRv/UWrCgsLcffuXdjY2Gh8LwgiIiL660qfjx8/hqurq9qN01721oeJu3fvqt2VkYiIiDSXlpaG6tWrlzj9rQ8TRbeSTUtLU96um4iIiF4vJycHbm5uym1pSd76MFG0a8PW1pZhgoiIqAxed5gAD8AkIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkeetv9EVElZsssfQbFBG9TUS8KJflcmSCiIiIJGGYICIiIkkYJoiIiEgShgkiIiKShGGCiIiIJGGYICIiIkkYJoiIiEgShgkiIiKShGGCiIiIJGGYICIiIkkYJoiIiEgShgkiIiKShGGCiIiIJGGYICIiIkkYJoiIiEgShgkiIiKShGGCiIiIJGGYICIiIkkYJoiIiEgShgkiIiKShGGCiIiIJGGYICIiIkkYJoiIiEgShgkiIiKShGGCiIiIJGGYICIiIkkYJoiIiEiScg0TM2bMQLNmzWBjYwNnZ2eEh4fjypUrKn3+/PNPDBs2DA4ODrC2tkbPnj1x//79cqqYiIiIXlWuYeLIkSMYNmwYfvrpJ+zfvx/Pnj1DSEgI8vLylH3GjBmD//znP9i6dSuOHDmCu3fvokePHuVYNREREb1MJoQQ5V1EkYyMDDg7O+PIkSNo3bo1srOz4eTkhA0bNqBXr14AgN9++w316tVDcnIy3nvvvdfOMycnBwqFAtnZ2bC1tdX3KhCRgZElysq7BKI3RsTrdpOu6TbUoI6ZyM7OBgDY29sDAH755Rc8e/YMHTp0UPapW7cuatSogeTk5GLnUVBQgJycHJUHERER6Y/BhInCwkKMHj0agYGBqF+/PgDg3r17MDMzg52dnUpfFxcX3Lt3r9j5zJgxAwqFQvlwc3PTd+lERESVmsGEiWHDhuHChQvYtGmTpPnExcUhOztb+UhLS9NRhURERFQck/IuAACGDx+O//73vzh69CiqV6+ubK9atSqePn2KrKwsldGJ+/fvo2rVqsXOSy6XQy6X67tkIiIi+p9yHZkQQmD48OH49ttv8f3338PT01NletOmTWFqaoqDBw8q265cuYLbt2+jefPmb7pcIiIiKka5jkwMGzYMGzZswM6dO2FjY6M8DkKhUMDCwgIKhQIDBw5EbGws7O3tYWtrixEjRqB58+YanclBRERE+leuYWLZsmUAgDZt2qi0r169GtHR0QCAefPmwcjICD179kRBQQFCQ0OxdOnSN1wpERERlcSgrjOhD7zOBFHlxutMUGXC60wQERFRhcQwQURERJIwTBAREZEkDBNEREQkCcMEERERScIwQURERJIwTBAREZEkDBNEREQkCcMEERERScIwQURERJIwTBAREZEkDBNEREQkCcMEERERScIwQURERJIwTBAREZEkDBNEREQkCcMEERERScIwQURERJIwTBAREZEkDBNEREQkCcMEERERScIwQURERJKYaNP58uXL2LRpE44dO4Zbt27hyZMncHJyQuPGjREaGoqePXtCLpfrq1YiIiIyQBqNTJw+fRodOnRA48aN8cMPPyAgIACjR4/GtGnT0K9fPwghMHHiRLi6umLWrFkoKCjQd91ERERkIDQamejZsyfGjRuHb775BnZ2diX2S05OxoIFCzB37lxMmDBBVzUSERGRAdMoTFy9ehWmpqav7de8eXM0b94cz549k1wYERERVQwa7ebQJEhI6U9EREQVl0YjEwsXLsSQIUNgbm6OhQsXltp35MiROimMiIiIKgaZEEK8rpOnpydOnToFBwcHeHp6ljwzmQw3btzQaYFS5eTkQKFQIDs7G7a2tuVdDhG9YbJEWXmXQPTGiPjXbtK1ouk2VKORidTU1GL/TURERMSLVhEREZEkGo1MxMbGajzDpKSkMhdDREREFY9GYeLMmTMqz0+fPo3nz5+jTp06AP46ddTY2BhNmzbVfYVERERk0DQKE4cOHVL+OykpCTY2NlizZg2qVKkCAHj06BE++OADtGrVSj9VEhERkcHS6GyOl73zzjvYt28ffH19VdovXLiAkJAQ3L17V6cFSsWzOYgqN57NQZVJeZ3NofUBmDk5OcjIyFBrz8jIwOPHj7WdHREREVVwWoeJ7t2744MPPsD27dtx584d3LlzB9u2bcPAgQPRo0cPfdRIREREBkyrW5ADwPLlyzF27Fj07dtXeQ8OExMTDBw4EHPmzNF5gURERGTYtD5mokheXh5SUlIAAN7e3rCystJpYbrCYyaIKjceM0GViUFfAbM4VlZW8PPzK+vLiYiI6C2hdZjIy8vDzJkzcfDgQaSnp6OwsFBluqHdm4OIiIj0S+swMWjQIBw5cgT9+/dHtWrVIJNxCJGIiKgy0zpM7N69G7t27UJgYKA+6iEiIqIKRutTQ6tUqQJ7e3t91EJEREQVkNZhYtq0aZgyZQqePHmij3qIiIiogtF6N8fcuXORkpICFxcXeHh4wNTUVGX66dOndVYcERERGT6tw0R4eLgeyiAiIqKKSuswER8fr486iIiIqIIq80WrfvnlF1y+fBkA4Ovri8aNG+usKCIiIqo4tA4T6enp6NOnDw4fPgw7OzsAQFZWFtq2bYtNmzbByclJ1zUSERGRAdP6bI4RI0bg8ePHuHjxIjIzM5GZmYkLFy4gJycHI0eO1EeNREREZMC0HpnYs2cPDhw4gHr16inbfHx8sGTJEoSEhOi0OCIiIjJ8Wo9MFBYWqp0OCgCmpqZq9+kgIiKit5/WYaJdu3YYNWoU7t69q2z7/fffMWbMGLRv316nxREREZHh0zpMLF68GDk5OfDw8IC3tze8vb3h6emJnJwcLFq0SKt5HT16FF27doWrqytkMhl27NihMj06OhoymUzlERYWpm3JREREpEdaHzPh5uaG06dP48CBA/jtt98AAPXq1UOHDh20XnheXh4aNmyImJgY9OjRo9g+YWFhWL16tfK5XC7XejlERESkP2W6zoRMJkNwcDCCg4MlLbxjx47o2LFjqX3kcjmqVq0qaTlERESkP1rv5hg5ciQWLlyo1r548WKMHj1aFzWpOHz4MJydnVGnTh18+OGHePjwYan9CwoKkJOTo/IgIiIi/dE6TGzbtg2BgYFq7S1atMA333yjk6KKhIWF4euvv8bBgwcxa9YsHDlyBB07dsSLFy9KfM2MGTOgUCiUDzc3N53WRERERKq03s3x8OFDKBQKtXZbW1s8ePBAJ0UV6dOnj/LfDRo0gJ+fH7y9vXH48OESzxyJi4tDbGys8nlOTg4DBRERkR5pPTJRs2ZN7NmzR6199+7d8PLy0klRJfHy8oKjoyOuX79eYh+5XA5bW1uVBxEREemP1iMTsbGxGD58ODIyMtCuXTsAwMGDBzF37lzMnz9f1/WpuHPnDh4+fIhq1arpdTlERESkOa3DRExMDAoKCvD5559j2rRpAAAPDw8sW7YMAwYM0Gpeubm5KqMMqampOHv2LOzt7WFvb4/ExET07NkTVatWRUpKCsaPH4+aNWsiNDRU27KJiIhIT2RCCFHWF2dkZMDCwgLW1tZlev3hw4fRtm1btfaoqCgsW7YM4eHhOHPmDLKysuDq6oqQkBBMmzYNLi4uGi8jJycHCoUC2dnZ3OVBVAnJEmXlXQLRGyPiy7xJL5am29AyXWfi+fPnOHz4MFJSUtC3b18AwN27d2Fra6tVsGjTpg1KyzJ79+4tS3lERET0BmkdJm7duoWwsDDcvn0bBQUFCA4Oho2NDWbNmoWCggIsX75cH3USERGRgdL6bI5Ro0bB398fjx49goWFhbK9e/fuOHjwoE6LIyIiIsOn9cjEsWPH8OOPP8LMzEyl3cPDA7///rvOCiMiIqKKQeuRicLCwmKvQHnnzh3Y2NjopCgiIiKqOLQOEyEhISrXk5DJZMjNzUV8fDw6deqky9qIiIioAtB6N8fcuXMRGhoKHx8f/Pnnn+jbty+uXbsGR0dHbNy4UR81EhERkQHTOkxUr14d586dw+bNm3Hu3Dnk5uZi4MCBiIyMVDkgk4iIiCqHMl1nwsTEBJGRkYiMjNR1PURERFTBaH3MxJo1a7Br1y7l8/Hjx8POzg4tWrTArVu3dFocERERGT6tw8T06dOVuzOSk5OxePFizJ49G46OjhgzZozOCyQiIiLDpvVujrS0NNSsWRMAsGPHDvTq1QtDhgxBYGAg2rRpo+v6iIiIyMBpPTJhbW2Nhw8fAgD27duH4OBgAIC5uTny8/N1Wx0REREZPK1HJoKDgzFo0CA0btwYV69eVV5b4uLFi/Dw8NB1fURERGTgtB6ZWLJkCZo3b46MjAxs27YNDg4OAIBffvkFEREROi+QiIiIDJtMlHYP8LeApvdiJ6K3kyxRVt4lEL0xIl63m3RNt6EajUzcvn1bq4Xzhl9ERESVh0ZholmzZhg6dCh+/vnnEvtkZ2dj5cqVqF+/PrZt26azAomIiMiwaXQA5qVLl/D5558jODgY5ubmaNq0KVxdXWFubo5Hjx7h0qVLuHjxIpo0aYLZs2fzhl9ERESViFbHTOTn52PXrl344YcfcOvWLeTn58PR0RGNGzdGaGgo6tevr89ay4THTBBVbjxmgiqT8jpmQqtTQy0sLNCrVy/06tVLcoFERET0dtD61FAiIiKilzFMEBERkSQME0RERCQJwwQRERFJwjBBREREkmh9oy8ASElJwfz583H58mUAgI+PD0aNGgVvb2+dFkdERESGT+uRib1798LHxwcnT56En58f/Pz8cOLECfj6+mL//v36qJGIiIgMmNYjE59++inGjBmDmTNnqrV/8sknCA4O1llxREREZPi0Hpm4fPkyBg4cqNYeExODS5cu6aQoIiIiqji0DhNOTk44e/asWvvZs2fh7Oysi5qIiIioAtF6N8fgwYMxZMgQ3LhxAy1atAAAHD9+HLNmzUJsbKzOCyQiIiLDpnWYmDx5MmxsbDB37lzExcUBAFxdXZGQkICRI0fqvEAiIiIybFrdNfRVjx8/BgDY2NjorCBd411DiSo33jWUKpMKcdfQVxlyiCAiIqI3Q6Mw0aRJExw8eBBVqlRB48aNIZOVnPRPnz6ts+KIiIjI8GkUJrp16wa5XA4ACA8P12c9REREVMFIOmaiIuAxE0SVG4+ZoMqkvI6Z4I2+iIiISBKNdnNUqVKl1OMkXpaZmSmpICIiIqpYNAoT8+fPV/774cOH+OyzzxAaGormzZsDAJKTk7F3715MnjxZL0USERGR4dL6mImePXuibdu2GD58uEr74sWLceDAAezYsUOX9UnGYyaIKjceM0GVSYU5ZmLv3r0ICwtTaw8LC8OBAwe0nR0RERFVcFqHCQcHB+zcuVOtfefOnXBwcNBJUURERFRxaH0FzMTERAwaNAiHDx9GQEAAAODEiRPYs2cPVq5cqfMCiYiIyLBpHSaio6NRr149LFy4ENu3bwcA1KtXDz/88IMyXBAREVHlUaZ7cwQEBGD9+vW6roWIiIgqoDJdtColJQWTJk1C3759kZ6eDgDYvXs3Ll68qNPiiIiIyPBpHSaOHDmCBg0a4MSJE9i2bRtyc3MBAOfOnUN8fLzOCyQiIiLDpnWY+PTTT/HZZ59h//79MDMzU7a3a9cOP/30k06LIyIiIsOndZg4f/48unfvrtbu7OyMBw8e6KQoIiIiqji0DhN2dnb4448/1NrPnDmDd955RydFERERUcWhdZjo06cPPvnkE9y7dw8ymQyFhYU4fvw4xo4diwEDBuijRiIiIjJgWoeJ6dOno27dunBzc0Nubi58fHzQunVrtGjRApMmTdJHjURERGTAtL7OhJmZGVauXInJkyfjwoULyM3NRePGjVGrVi191EdEREQGrkzXmQCAGjVqoFOnTnj//ffLHCSOHj2Krl27wtXVFTKZTO2Oo0IITJkyBdWqVYOFhQU6dOiAa9eulbVkIiIi0gONRyamTp2qUb8pU6ZovPC8vDw0bNgQMTEx6NGjh9r02bNnY+HChVizZg08PT0xefJkhIaG4tKlSzA3N9d4OURERKQ/MiGERjc/NzIygqurK5ydnVHSS2QyGU6fPl22QmQyfPvttwgPDwfw16iEq6srPv74Y4wdOxYAkJ2dDRcXF3z11Vfo06ePRvPV9F7sRPR2kiXKyrsEojdGxGu0SdeYpttQjUcmOnbsiO+//x7+/v6IiYlBly5dYGRU5r0kr5Wamop79+6hQ4cOyjaFQoGAgAAkJydrHCaIiIhIvzROA7t27UJKSgoCAgIwbtw4vPPOO/jkk09w5coVvRR27949AICLi4tKu4uLi3JacQoKCpCTk6PyICIiIv3RamjB1dUVcXFxuHLlCjZv3oz09HQ0a9YMgYGByM/P11eNWpkxYwYUCoXy4ebmVt4lERERvdXKvJ+iWbNmaNu2LerVq4czZ87g2bNnuqwLVatWBQDcv39fpf3+/fvKacWJi4tDdna28pGWlqbTuoiIiEiV1mEiOTkZgwcPRtWqVbFo0SJERUXh7t27Oj+40dPTE1WrVsXBgweVbTk5OThx4gSaN29e4uvkcjlsbW1VHkRERKQ/Gh+AOXv2bHz11Vd48OABIiMjcezYMfj5+UlaeG5uLq5fv658npqairNnz8Le3h41atTA6NGj8dlnn6FWrVrKU0NdXV2VZ3wQERFR+dPq1NAaNWqgS5cuKrcef1VSUpLGCz98+DDatm2r1h4VFYWvvvoKQgjEx8djxYoVyMrKQsuWLbF06VLUrl1b42Xw1FCiyo2nhlJlUl6nhmocJtq0aQOZrPQvpUwmw/fff69dpXrGMEFUuTFMUGVi8NeZOHz4sC7qIiIioreM/q46RURERJUCwwQRERFJwjBBREREkjBMEBERkSQME0RERCSJxmdzvCwrKwurVq3C5cuXAQC+vr6IiYmBQqHQaXFERERk+LQemTh16hS8vb0xb948ZGZmIjMzE0lJSfD29sbp06f1USMREREZMK1HJsaMGYO//e1vWLlyJUxM/nr58+fPMWjQIIwePRpHjx7VeZFERERkuLQOE6dOnVIJEgBgYmKC8ePHw9/fX6fFERERkeHTejeHra0tbt++rdaelpYGGxsbnRRFREREFYfWYaJ3794YOHAgNm/ejLS0NKSlpWHTpk0YNGgQIiIi9FEjERERGTCtd3P885//hEwmw4ABA/D8+XMAgKmpKT788EPMnDlT5wUSERGRYdP4rqGvevLkCVJSUgAA3t7esLS01GlhusK7hhJVbrxrKFUmBn/X0FdZWlrCzs5O+W8iIiKqnLQ+ZuL58+eYPHkyFAoFPDw84OHhAYVCgUmTJuHZs2f6qJGIiIgMmNYjEyNGjMD27dsxe/ZsNG/eHACQnJyMhIQEPHz4EMuWLdN5kURERGS4tA4TGzZswKZNm9CxY0dlm5+fH9zc3BAREcEwQUREVMlovZtDLpfDw8NDrd3T0xNmZma6qImIiIgqEK3DxPDhwzFt2jQUFBQo2woKCvD5559j+PDhOi2OiIiIDJ/WuznOnDmDgwcPonr16mjYsCEA4Ny5c3j69Cnat2+PHj16KPtu375dd5USERGRQdI6TNjZ2aFnz54qbW5ubjoriIiIiCoWrcPE6tWr9VEHERERVVBaHzNBRERE9DKtRyYePnyIKVOm4NChQ0hPT0dhYaHK9MzMTJ0VR0RERIZP6zDRv39/XL9+HQMHDoSLiwtkMl73noiIqDLTOkwcO3YMP/zwg/JMDiIiIqrctD5mom7dusjPz9dHLURERFQBaR0mli5diokTJ+LIkSN4+PAhcnJyVB5ERERUuZTpOhM5OTlo166dSrsQAjKZDC9evNBZcURERGT4tA4TkZGRMDU1xYYNG3gAJhEREWkfJi5cuIAzZ86gTp06+qinwmCGospEiPKugIgMmdbHTPj7+yMtLU0ftRAREVEFpPXIxIgRIzBq1CiMGzcODRo0gKmpqcp0Pz8/nRVHREREhk/rMNG7d28AQExMjLJNJpPxAEwiIqJKSuswkZqaqo86iIiIqILSOky4u7vrow4iIiKqoMp019C1a9ciMDAQrq6uuHXrFgBg/vz52Llzp06LIyIiIsOndZhYtmwZYmNj0alTJ2RlZSmPkbCzs8P8+fN1XR8REREZOK3DxKJFi7By5UpMnDgRxsbGynZ/f3+cP39ep8URERGR4dM6TKSmpqJx48Zq7XK5HHl5eTopioiIiCoOrcOEp6cnzp49q9a+Z88e1KtXTxc1ERERUQWi8dkcU6dOxdixYxEbG4thw4bhzz//hBACJ0+exMaNGzFjxgx88cUX+qyViIiIDJBMCM2uum9sbIw//vgDzs7OWL9+PRISEpCSkgIAcHV1RWJiIgYOHKjXYssiJycHCoUC2dnZsLW11dl8eW8Oqkwq8r05ZIn8slLlIeJ1+2XVdBuq8cjEy5kjMjISkZGRePLkCXJzc+Hs7CytWiIiIqqwtLpo1au3G7e0tISlpaVOCyIiIqKKRaswUbt2bbVA8arMzExJBREREVHFolWYSExMhEKh0FctREREVAFpFSb69OnD4yOIiIhIhcbXmXjd7g0iIiKqnDQOExqeQUpERESVjMa7OQoLC/VZBxEREVVQZboFOREREVERhgkiIiKShGGCiIiIJDHoMJGQkACZTKbyqFu3bnmXRURERC/R6joT5cHX1xcHDhxQPjcxMfiSiYiIKhWD3zKbmJigatWq5V0GERERlcCgd3MAwLVr1+Dq6govLy9ERkbi9u3bpfYvKChATk6OyoOIiIj0x6DDREBAAL766ivs2bMHy5YtQ2pqKlq1aoXHjx+X+JoZM2ZAoVAoH25ubm+wYiIiospHJirQpS2zsrLg7u6OpKQkDBw4sNg+BQUFKCgoUD7PycmBm5sbsrOzYWtrq7NaeHVxqkwqzq+EOlkiv6xUeYh43X5Zc3JyoFAoXrsNNfhjJl5mZ2eH2rVr4/r16yX2kcvlkMvlb7AqIiKiys2gd3O8Kjc3FykpKahWrVp5l0JERET/Y9BhYuzYsThy5Ahu3ryJH3/8Ed27d4exsTEiIiLKuzQiIiL6H4PezXHnzh1ERETg4cOHcHJyQsuWLfHTTz/BycmpvEsjIiKi/zHoMLFp06byLoGIiIhew6B3cxAREZHhY5ggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSSpEmFiyZAk8PDxgbm6OgIAAnDx5srxLIiIiov8x+DCxefNmxMbGIj4+HqdPn0bDhg0RGhqK9PT08i6NiIiIUAHCRFJSEgYPHowPPvgAPj4+WL58OSwtLfHll1+Wd2lEREQEwKS8CyjN06dP8csvvyAuLk7ZZmRkhA4dOiA5ObnY1xQUFKCgoED5PDs7GwCQk5Oj32KJ3mIV+uvzZ3kXQPTm6HpbVzQ/IUSp/Qw6TDx48AAvXryAi4uLSruLiwt+++23Yl8zY8YMJCYmqrW7ubnppUaiykChKO8KiEgTipn6+bI+fvwYilJ+CAw6TJRFXFwcYmNjlc8LCwuRmZkJBwcHyGSycqyMpMrJyYGbmxvS0tJga2tb3uUQUQn4XX17CCHw+PFjuLq6ltrPoMOEo6MjjI2Ncf/+fZX2+/fvo2rVqsW+Ri6XQy6Xq7TZ2dnpq0QqB7a2tvyBIqoA+F19O5Q2IlHEoA/ANDMzQ9OmTXHw4EFlW2FhIQ4ePIjmzZuXY2VERERUxKBHJgAgNjYWUVFR8Pf3x7vvvov58+cjLy8PH3zwQXmXRkRERKgAYaJ3797IyMjAlClTcO/ePTRq1Ah79uxROyiT3n5yuRzx8fFqu7GIyLDwu1r5yMTrzvcgIiIiKoVBHzNBREREho9hgoiIiCRhmCAiIiJJGCaoQmnTpg1Gjx5d3mUQUSn4Pa18GCbojYiOjoZMJsPMmTNV2nfs2KHVlUm3b9+OadOm6bo8orfKvXv3MGrUKNSsWRPm5uZwcXFBYGAgli1bhidPnpR3eQAADw8PyGQyyGQyWFpaokGDBvjiiy+K7btx40YYGxtj2LBhxU7PycnB5MmT4evrCwsLCzg4OKBZs2aYPXs2Hj16pM/VoP9hmKA3xtzcHLNmzZL05ba3t4eNjY0OqyJ6u9y4cQONGzfGvn37MH36dJw5cwbJyckYP348/vvf/+LAgQPFvu7Zs2dvuFJg6tSp+OOPP3DhwgX069cPgwcPxu7du9X6rVq1CuPHj8fGjRvx55+qd27LzMzEe++9h9WrV2Ps2LE4ceIETp8+jc8//xxnzpzBhg0b3tTqVG6C6A2IiooSXbp0EXXr1hXjxo1Ttn/77bei6GP44MED0adPH+Hq6iosLCxE/fr1xYYNG1TmExQUJEaNGiWEECIuLk68++67asvy8/MTiYmJyucrV64UdevWFXK5XNSpU0csWbJED2tIZBhCQ0NF9erVRW5ubrHTCwsLhRBCABBLly4VXbt2FZaWliI+Pl48f/5cxMTECA8PD2Fubi5q164t5s+fr/L6qKgo0a1bN5GQkCAcHR2FjY2NGDp0qCgoKFD2CQoKEiNGjBDjxo0TVapUES4uLiI+Pl5lPu7u7mLevHkqbfb29mLMmDEqbTdu3BAWFhYiKytLBAQEiPXr16tMHzp0qLCyshK///57qetL+sWRCXpjjI2NMX36dCxatAh37txRm/7nn3+iadOm2LVrFy5cuIAhQ4agf//+OHnyZLHzi4yMxMmTJ5GSkqJsu3jxIn799Vf07dsXALB+/XpMmTIFn3/+OS5fvozp06dj8uTJWLNmjX5WkqgcPXz4EPv27cOwYcNgZWVVbJ+XdysmJCSge/fuOH/+PGJiYlBYWIjq1atj69atuHTpEqZMmYIJEyZgy5YtKvM4ePAgLl++jMOHD2Pjxo3Yvn272t2a16xZAysrK5w4cQKzZ8/G1KlTsX///mJrKiwsxLZt2/Do0SOYmZmpTFu9ejU6d+4MhUKBfv36YdWqVSqv27x5M/r161fijah4g8c3pLzTDFUORX/NCCHEe++9J2JiYoQQqiMTxencubP4+OOPlc9fHpkQQoiGDRuKqVOnKp/HxcWJgIAA5XNvb2+10Y1p06aJ5s2bS1kdIoP0008/CQBi+/btKu0ODg7CyspKWFlZifHjxwsh/hqZGD169GvnOWzYMNGzZ0/l86ioKGFvby/y8vKUbcuWLRPW1tbixYsXQoi/vqctW7ZUmU+zZs3EJ598onzu7u4uzMzMhJWVlTAxMREAhL29vbh27Zqyz4sXL4Sbm5vYsWOHEEKIjIwMYWZmJm7cuCGEEOLevXsCgEhKSlJZVpMmTZTr26dPn9euI0nHkQl642bNmoU1a9bg8uXLKu0vXrzAtGnT0KBBA9jb28Pa2hp79+7F7du3S5xXZGSkcp+oEAIbN25EZGQkACAvLw8pKSkYOHAgrK2tlY/PPvtMZTSD6G138uRJnD17Fr6+vigoKFC2+/v7q/VdsmQJmjZtCicnJ1hbW2PFihVq38GGDRvC0tJS+bx58+bIzc1FWlqass3Pz0/lNdWqVUN6erpK27hx43D27Fl8//33CAgIwLx581CzZk3l9P379yMvLw+dOnUC8NedpIODg/Hll1+Wur7ffvstzp49i9DQUOTn55fal3TD4O/NQW+f1q1bIzQ0FHFxcYiOjla2z5kzBwsWLMD8+fPRoEEDWFlZYfTo0Xj69GmJ84qIiMAnn3yC06dPIz8/H2lpaejduzcAIDc3FwCwcuVKBAQEqLzO2NhY9ytGVM5q1qwJmUyGK1euqLR7eXkBACwsLFTaX90VsmnTJowdOxZz585F8+bNYWNjgzlz5uDEiRNa12JqaqryXCaTobCwUKXN0dERNWvWRM2aNbF161Y0aNAA/v7+8PHxAfDXgZeZmZkqdRcWFuLXX39FYmIinJycYGdnp7a+NWrUAADY2NggKytL69pJewwTVC5mzpyJRo0aoU6dOsq248ePo1u3bujXrx+Av340rl69qvxhKU716tURFBSE9evXIz8/H8HBwXB2dgYAuLi4wNXVFTdu3FCOVhC9zRwcHBAcHIzFixdjxIgRJR43UZLjx4+jRYsW+Oijj5RtxY3inTt3Dvn5+cqN/E8//QRra2u4ubmVuXY3Nzf07t0bcXFx2LlzJx4+fIidO3di06ZN8PX1VfZ78eIFWrZsiX379iEsLAzvv/8+1q1bhylTppR43ATpH8MElYsGDRogMjISCxcuVLbVqlUL33zzDX788UdUqVIFSUlJuH//fqlhAvhrV0d8fDyePn2KefPmqUxLTEzEyJEjoVAoEBYWhoKCApw6dQqPHj1CbGysXtaNqDwtXboUgYGB8Pf3R0JCAvz8/GBkZISff/4Zv/32G5o2bVria2vVqoWvv/4ae/fuhaenJ9auXYuff/4Znp6eKv2ePn2KgQMHYtKkSbh58ybi4+MxfPhwGBlJ23M+atQo1K9fH6dOncIPP/wABwcHvP/++2oHUXbq1AmrVq1CWFgYpk+fjsOHD+Pdd9/F1KlT4e/vDysrK/z6669ITk5G/fr1JdVEmmGYoHIzdepUbN68Wfl80qRJuHHjBkJDQ2FpaYkhQ4YgPDwc2dnZpc6nV69eGD58OIyNjREeHq4ybdCgQbC0tMScOXMwbtw4WFlZoUGDBrw6H721vL29cebMGUyfPh1xcXG4c+cO5HI5fHx8MHbsWJVRh1cNHToUZ86cQe/evSGTyRAREYGPPvpI7doP7du3R61atdC6dWsUFBQgIiICCQkJkmv38fFBSEgIpkyZgjt37qB79+7Fno3Rs2dP9O/fHw8ePICjoyNOnjyJWbNmYc6cOUhNTYWRkRFq1aqF3r1787v+hvAW5EREpLHo6GhkZWVhx44d5V0KGRCezUFERESSMEwQERGRJNzNQURERJJwZIKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgkYZggIiIiSRgmiIiISBKGCSIiIpKEYYKIiIgk+T/Q5LyfvbPsUwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(['Naive', 'GraphRAG'], [mean_global_naive, mean_global_graph], color=['blue', 'green'])\n",
    "plt.title('Confronto Tempi Medi: Naive vs GraphRAG')\n",
    "plt.ylabel('Tempo Medio (secondi)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Valutazione su domande locali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 GraphRAG su domande locali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Selezione file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_covariates,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_relationships,\n",
    "    read_indexer_reports,\n",
    "    read_indexer_text_units,\n",
    ")\n",
    "from graphrag.query.input.loaders.dfs import (\n",
    "    store_entity_semantic_embeddings,\n",
    ")\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.embedding import OpenAIEmbedding\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.question_gen.local_gen import LocalQuestionGen\n",
    "from graphrag.query.structured_search.local_search.mixed_context import (\n",
    "    LocalSearchMixedContext,\n",
    ")\n",
    "from graphrag.query.structured_search.local_search.search import LocalSearch\n",
    "from graphrag.vector_stores.lancedb import LanceDBVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path exists and is not empty.\n"
     ]
    }
   ],
   "source": [
    "file_path = '../../output/20241001-101207/artifacts'\n",
    "\n",
    "if not os.path.exists(file_path) or not os.listdir(file_path):\n",
    "    print(\"The specified path is empty or does not exist.\")\n",
    "else:\n",
    "    print(\"The path exists and is not empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = file_path\n",
    "LANCEDB_URI = f\"{INPUT_DIR}/lancedb\"\n",
    "\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "RELATIONSHIP_TABLE = \"create_final_relationships\"\n",
    "COVARIATE_TABLE = \"create_final_covariates\"\n",
    "TEXT_UNIT_TABLE = \"create_final_text_units\"\n",
    "COMMUNITY_LEVEL = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "nodes_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "relationship_df = pd.read_parquet(f\"{INPUT_DIR}/{RELATIONSHIP_TABLE}.parquet\")\n",
    "df_report = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)\n",
    "\n",
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "\n",
    "relationship_df = pd.read_parquet(f\"{INPUT_DIR}/{RELATIONSHIP_TABLE}.parquet\")\n",
    "relationships = read_indexer_relationships(relationship_df)\n",
    "\n",
    "text_unit_df = pd.read_parquet(f\"{INPUT_DIR}/{TEXT_UNIT_TABLE}.parquet\")\n",
    "text_units = read_indexer_text_units(text_unit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "\n",
    "# load description embeddings to an in-memory lancedb vectorstore\n",
    "description_embedding_store = LanceDBVectorStore(\n",
    "    collection_name=\"entity_description_embeddings\",\n",
    ")\n",
    "description_embedding_store.connect(db_uri=LANCEDB_URI)\n",
    "entity_description_embeddings = store_entity_semantic_embeddings(\n",
    "    entities=entities, vectorstore=description_embedding_store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Definzione dei modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"GRAPHRAG_API_KEY\"]\n",
    "\n",
    "llm_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "api_base = \"http://172.18.21.132:8000/v1\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    model=llm_model,\n",
    "    api_type=OpenaiApiType.OpenAI,  \n",
    "    api_base=api_base,  \n",
    "    max_retries=20,\n",
    ")\n",
    "\n",
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = \"nextfire/paraphrase-multilingual-minilm:l12-v2\"  \n",
    "api_base = \"http://localhost:11434/api/embeddings\"\n",
    "\n",
    "text_embedder = OpenAIEmbedding(\n",
    "    api_key=api_key,\n",
    "    api_base=api_base,  \n",
    "    api_type=OpenaiApiType.OpenAI,  \n",
    "    model=embedding_model,\n",
    "    deployment_name=embedding_model,  \n",
    "    max_retries=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Creazione query-engine per domande locali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder = LocalSearchMixedContext(\n",
    "    community_reports=reports,\n",
    "    text_units=text_units,\n",
    "    entities=entities,\n",
    "    relationships=relationships,\n",
    "    covariates=None, \n",
    "    entity_text_embeddings=description_embedding_store,\n",
    "    embedding_vectorstore_key=EntityVectorStoreKey.ID,  \n",
    "    text_embedder=text_embedder,\n",
    "    token_encoder=token_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_context_params = {\n",
    "    \"text_unit_prop\": 0.5,\n",
    "    \"community_prop\": 0.1,\n",
    "    \"conversation_history_max_turns\": 5,\n",
    "    \"conversation_history_user_turns_only\": True,\n",
    "    \"top_k_mapped_entities\": 20,\n",
    "    \"top_k_relationships\": 20,\n",
    "    \"include_entity_rank\": True,\n",
    "    \"include_relationship_weight\": True,\n",
    "    \"include_community_rank\": False,\n",
    "    \"return_candidate_context\": False,\n",
    "    \"embedding_vectorstore_key\": EntityVectorStoreKey.ID,  \n",
    "    \"max_tokens\": 6000,  \n",
    "}\n",
    "\n",
    "llm_params = {\n",
    "    \"max_tokens\": 1000, \n",
    "    \"temperature\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine_local = LocalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    llm_params=llm_params,\n",
    "    context_builder_params=local_context_params,\n",
    "    response_type=\"Single page\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Funzioni per esecuzione delle query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask_question_graph_local(question):\n",
    "    try:\n",
    "        result = await search_engine_local.asearch(question)\n",
    "        answer = result.response\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question: {question}\\nException: {e}\")\n",
    "        answer = \"Error: Unable to retrieve answer.\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_local_graph(question):\n",
    "    answer = await ask_question_graph_local(question)\n",
    "    display(Markdown(f\"**Domanda:** {question}\\n\\n**Risposta:**\\n{answer}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 RAG Tradizionale su domande locali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene utilizzata la pipeline definita per le domande globali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Confronto su domande locali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Selezione di 5 domande locali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_local1 = \"What is the result of the comprehensive evaluation of Chronos models on 42 datasets, as reported in the paper?\"\n",
    "query_local2 = \"What is the architecture of TimeGPT, as described in Section 5.1 of the paper?\"\n",
    "query_local3 = \"How does the tokenization scheme of Lag-Llama work, as described in Section 4.1 of the paper?\"\n",
    "query_local4 = \"What is the evaluation metric used to compare the performance of AnomalyBERT with previous works, as described in Section 4.2?\"\n",
    "query_local5 = \"According to the paper 'Foundation Models for Time Series Analysis: A Tutorial and Survey', what is the primary difference between the proposed taxonomy and previous taxonomies?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Confronto risposte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.1 Prima Query locale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GraphRAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: No community records added when building community context.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What is the result of the comprehensive evaluation of Chronos models on 42 datasets, as reported in the paper?\n",
       "\n",
       "**Risposta:**\n",
       "**Comprehensive Evaluation of Chronos Models**\n",
       "=============================================\n",
       "\n",
       "The paper reports the results of a comprehensive evaluation of Chronos models on 42 datasets, which are divided into three categories: pretraining-only, in-domain evaluation, and zero-shot evaluation.\n",
       "\n",
       "**Pretraining-Only Datasets**\n",
       "-----------------------------\n",
       "\n",
       "The pretraining-only datasets are used to train Chronos models, and the results are not reported in the paper. However, the paper mentions that 13 datasets are used for pretraining, which includes:\n",
       "\n",
       "* Brazilian Cities Temperature\n",
       "* Mexico City Bikes\n",
       "* Solar (5 Min.)\n",
       "* Solar (Hourly)\n",
       "* Spanish Energy and Weather\n",
       "* Taxi (Hourly)\n",
       "* USHCN\n",
       "* Weatherbench (Daily)\n",
       "* Weatherbench (Hourly)\n",
       "\n",
       "**In-Domain Evaluation Datasets**\n",
       "---------------------------------\n",
       "\n",
       "The in-domain evaluation datasets are used to evaluate the performance of Chronos models, and the results are reported in the paper. The paper reports the results of Chronos models on 15 in-domain evaluation datasets, which includes:\n",
       "\n",
       "* Australian Electricity\n",
       "* Electricity (15 Min., Hourly, Weekly)\n",
       "* ERCOT Load\n",
       "* ETT (15 Min., Hourly)\n",
       "* Brazilian Cities Temperature\n",
       "* Mexico City Bikes\n",
       "* Solar (5 Min.)\n",
       "* Solar (Hourly)\n",
       "* Spanish Energy and Weather\n",
       "* Taxi (Hourly)\n",
       "* USHCN\n",
       "* Weatherbench (Daily)\n",
       "* Weatherbench (Hourly)\n",
       "* Electricity\n",
       "* ETT\n",
       "\n",
       "The results show that Chronos models outperform local statistical models on these datasets, with an average improvement of 10.2% in terms of WQL and 12.5% in terms of MASE.\n",
       "\n",
       "**Zero-Shot Evaluation Datasets**\n",
       "---------------------------------\n",
       "\n",
       "The zero-shot evaluation datasets are used to evaluate the performance of Chronos models on unseen datasets, and the results are reported in the paper. The paper reports the results of Chronos models on 27 zero-shot evaluation datasets, which includes:\n",
       "\n",
       "* All the datasets in Benchmark II\n",
       "\n",
       "The results show that Chronos models outperform local statistical models on these datasets, with an average improvement of 15.6% in terms of WQL and 18.2% in terms of MASE.\n",
       "\n",
       "**Overall Results**\n",
       "-------------------\n",
       "\n",
       "The overall results of the comprehensive evaluation of Chronos models on 42 datasets are reported in the paper. The results show that Chronos models outperform local statistical models on all three categories of datasets, with an average improvement of 12.5% in terms of WQL and 15.1% in terms of MASE.\n",
       "\n",
       "**Data References**\n",
       "-------------------\n",
       "\n",
       "This result is supported by multiple data references:\n",
       "\n",
       "* Data: Benchmark I (1-15), Benchmark II (1-27), Pretraining-only datasets (1-13)\n",
       "* Data: In-domain evaluation datasets (1-15), Zero-shot evaluation datasets (1-27)\n",
       "* Data: Overall results (Benchmark I, Benchmark II, Pretraining-only datasets, In-domain evaluation datasets, Zero-shot evaluation datasets)\n",
       "\n",
       "Note that the record ids are not provided in the paper, but the above references provide a general idea of the datasets used in the evaluation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await test_local_graph(query_local1)\n",
    "\n",
    "end_time = time.time()\n",
    "time_local_graph1 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG tradizionale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload inviato all'API: {'prompt': '\\nYou are a knowledgeable assistant specialized in answering questions based solely on the provided context. Provide a detailed and well-structured answer, including all relevant information from the context. Ensure your response is comprehensive, faithful to the context, and presented in clear, well-formed sentences. Do not add any information that is not present in the context. If the answer is not explicitly stated in the context, respond with \"I don\\'t know.\"\\n\\nContext:\\n# 5.1 Datasets\\n\\nTo train and evaluate Chronos models, we collected a wide variety of publicly available datasets spanning various application domains including energy, transport, healthcare, retail, web, weather, finance, and with sampling frequencies ranging from 5 minutes up to yearly. The complete list of datasets, together with their respective sources and additional details, is given in Appendix B. In total, our dataset collection comprises 55 datasets from multiple sources, including the Monash Time Series Forecasting Repository (Godahewa et al., 2021), the M-competitions (Makridakis et al., 1979; Makridakis & Hibon, 2000; Makridakis et al., 2020; 2022), and public domain datasets from Kaggle.\\n\\n. Overall, we used 28 datasets for training Chronos models, consisting of about 890K univariate time series with approximately 84B observations (tokens) in total. For both in-domain (I) and zero-shot (II) benchmark datasets, we used the last H ∈ N+ observations of each time series as a held-out test set: all models are judged by the accuracy of their forecast on such held-out set, which no model had access to for training purposes. The prediction\\n\\nWe categorize this collection into three subsets, based on how we use them for training and evaluating Chronos models: (a) datasets exclusively used for training (13 datasets); (b) Benchmark I datasets, employed for both training and evaluation, representing an in-domain evaluation (15 datasets); and (c) Benchmark II datasets, used solely for evaluation, constituting a zero-shot evaluation (27 datasets). In categorizing the datasets in this way, we tried to find a good balance between keeping as many datasets as possible for the zero-shot evaluation of Chronos models, among the ones most commonly used in the literature, while still having enough variety of domains and sampling frequencies in the training data. Overall, we used 28 datasets for training Chronos models, consisting of about 890K univariate time series with approximately 84B observations (tokens) in total\\n\\nOur code and model checkpoints are available at https://github.com/amazon-science/chronos-forecasting.\\n\\nSome models (GPT4TS and ForecastPFN) only generate point forecasts and we only evaluate those.\\n# 5.5 Main Results\\n\\nIn this section, we present our main results on 42 datasets, which comprise Benchmark I (15 datasets) and Benchmark II (27 datasets). Chronos models surpass classical statistical baselines, task-specific deep learning models, and other pretrained models on the in-domain datasets (Benchmark I; see Section 5.5.1). On the zero-shot datasets (Benchmark II; Section 5.5.2), Chronos models comfortably outperform statistical baselines and other pretrained models, while performing on par with the best deep learning models trained on these tasks. With an inexpensive fine-tuning regimen, our Chronos-T5 (Small) model achieves the top spot on Benchmark II, significantly outperforming all baselines.\\n\\n# 5.5.1 Benchmark I: In-domain Results\\n\\n# Fine tuning\\n\\nMotivated by the remarkable zero-shot performance of Chronos models, we conducted a preliminary investigation into fine-tuning Chronos models individually on datasets from Benchmark II.\\n\\n|Chronos-T5 (Small)|Zero Shot|Fine Tuned|\\n|---|---|---|\\n|WQL|0.672|0.608|\\n|MASE|0.856|0.782|\\n\\nQuestion:\\nWhat is the result of the comprehensive evaluation of Chronos models on 42 datasets, as reported in the paper?\\n\\nAnswer:\\n', 'model': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'temperature': 0.0, 'max_tokens': 500, 'repetition_penalty': 1.2, 'stop': [\"I don't know.\"]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What is the result of the comprehensive evaluation of Chronos models on 42 datasets, as reported in the paper?\n",
       "\n",
       "**Risposta:** According to the text, the comprehensive evaluation of Chronos models on 42 datasets shows that they surpass classical statistical baselines, task-specific deep learning models, and other pre-trained models on the in-domain datasets (Benchmark I). Additionally, on the zero-shot datasets (Benchmark II), Chronos models comfortably outperform statistical baselines and other pre-trained models, while performing on par with the best deep learning models trained on these tasks. Furthermore, it was found that with an inexpensive fine-tuning regimen, the Chronos-T5 (Small) model achieved the top spot on Benchmark II, significantly outperforming all baselines. This suggests that Chronos models exhibit strong performance across different types of datasets and evaluation settings. \n",
       "\n",
       "Note: The question does not ask specifically what the results were but rather asks for the overall outcome or conclusion drawn from the evaluation. Therefore, my answer focuses on summarizing the key findings mentioned in the passage without providing specific numerical values unless directly asked for. However, if you'd like me to extract more precise metrics related to the performance of Chronos models, please let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await ask_question_naive(query_local1)\n",
    "\n",
    "end_time = time.time()\n",
    "time_local_naive1 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.2 Seconda Query locale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GraphRAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What is the architecture of TimeGPT, as described in Section 5.1 of the paper?\n",
       "\n",
       "**Risposta:**\n",
       "**TimeGPT Architecture**\n",
       "==========================\n",
       "\n",
       "According to Section 5.1 of the paper, the architecture of TimeGPT is described as follows:\n",
       "\n",
       "**Patching**\n",
       "------------\n",
       "\n",
       "TimeGPT uses a patching technique, inspired by the success of patch-based modeling in long-horizon forecasting work. This involves breaking down the time series into patches during training, where a patch is a natural analogue for a token in language models. Patching improves performance and inference speed by reducing the number of tokens fed into the transformer.\n",
       "\n",
       "**Transformer Architecture**\n",
       "---------------------------\n",
       "\n",
       "The TimeGPT architecture is based on a transformer model, which has been shown to be effective in adapting to different context lengths in NLP. The transformer architecture consists of multiple layers, including:\n",
       "\n",
       "* **Multi-Head Attention**: This layer allows the model to attend to different parts of the input sequence simultaneously and weigh their importance.\n",
       "* **CNN**: This layer is used for convolutional neural network operations.\n",
       "* **Add & Norm**: This layer is used for adding and normalizing the output of the previous layers.\n",
       "* **Multi-Head Masked Attention**: This layer is used for masked attention, where the model attends to the input sequence while ignoring certain positions.\n",
       "* **Additional Variables**: This layer is used for additional variables, such as positional encoding and embedding.\n",
       "\n",
       "**Positional Encoding**\n",
       "----------------------\n",
       "\n",
       "TimeGPT uses positional encoding to capture the temporal relationships between different time steps. This is achieved by adding a positional encoding vector to the input embedding.\n",
       "\n",
       "**Embedding**\n",
       "------------\n",
       "\n",
       "The input embedding is used to represent the input time series data in a high-dimensional space. This is achieved by using a learned embedding matrix.\n",
       "\n",
       "**Output**\n",
       "----------\n",
       "\n",
       "The output of the TimeGPT model is a forecast of the future time series values. This is achieved by using a decoder-only architecture, where the model takes the historical values of the target values and additional exogenous variables as inputs to produce the forecasts.\n",
       "\n",
       "**Data References**\n",
       "-------------------\n",
       "\n",
       "This information is supported by the following data references:\n",
       "\n",
       "* [Data: Paper (120), Section 5.1]\n",
       "* [Data: Architecture (1), TimeGPT (2)]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await test_local_graph(query_local2)\n",
    "\n",
    "end_time = time.time()\n",
    "time_local_graph2 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG tradizionale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload inviato all'API: {'prompt': '\\nYou are a knowledgeable assistant specialized in answering questions based solely on the provided context. Provide a detailed and well-structured answer, including all relevant information from the context. Ensure your response is comprehensive, faithful to the context, and presented in clear, well-formed sentences. Do not add any information that is not present in the context. If the answer is not explicitly stated in the context, respond with \"I don\\'t know.\"\\n\\nContext:\\n# 5 TimeGPT\\n\\n# 5.1 Architecture\\n\\nTimeGPT is a Transformer-based time series model with self-attention mechanisms based on [Vaswani et al., 2017]. TimeGPT takes a window of historical values to produce the forecast, adding local positional encoding to enrich the input. The architecture consists of an encoder-decoder structure with multiple layers, each with residual connections and layer normalization. Finally, a linear layer maps the decoder’s output to the forecasting window dimension. The general intuition is that attention-based mechanisms are able to capture the diversity of past events and correctly extrapolate potential future distributions.\\n\\n# 5.3 Training TimeGPT\\n\\nTimeGPT underwent a multi-day training period on a cluster of NVIDIA A10G GPUs. During this process, we carried out extensive hyperparameter exploration to optimize learning rates, batch sizes, and other related parameters. We observed a pattern in alignment with findings from [Brown et al., 2020], where a larger batch size and a smaller learning rate proved beneficial. Implemented in PyTorch, TimeGPT was trained using the Adam with a learning rate decay strategy that reduced the rate to 12% of its initial value.\\n\\n# 5.4 Uncertainty quantification\\n\\nWe selected T5 (Raffel et al., 2020) as the main architecture for Chronos in our experiments, since it is available in a variety of sizes, ranging from 16M (Tiny) to 11B (XXL) parameters (Tay et al., 2021). We also conducted experiments with the decoder-only GPT-2 model to demonstrate the applicability of the Chronos framework to decoder-only models. In the following, we discuss the training configurations used for our main results (Section 5.5) and explore alternatives for some of the hyperparameters in Section 5.6.\\n\\n# A PREPRINT\\n\\n# Figure 1\\n\\nWe provide an illustration of the TimesFM model architecture during training, where we show a input time-series of a specific length that can be broken down into input patches. Each patch along is processed into a vector by a residual block (as defined in the model definition) to the model dimension of the transformer layers. The vector is then added to positional encodings and fed into nl stacked transformer layers. SA refers to self-attention (note that we use multi-head causal attention) and FFN is the fully connected layer in the transformer. The output tokens are then mapped through a residual block to an output of size output_patch_len, which is the forecast for the time window following the last input patch seen by the model so far.\\n\\n# Network\\n\\n# 6.3 Time Comparison\\n\\nFor zero-shot inference, our internal tests recorded an average GPU inference speed of 0.6 milliseconds per series for TimeGPT, which nearly mirrors that of the simple Seasonal Naive. As points of comparison, we consider parallel computing-optimized statistical methods, which, when complemented with Numba compiling, averaged a speed of 600 milliseconds per series for training and inference. On the other hand, global models such as LGBM, LSTM, and NHITS demonstrated a more prolonged average of 57 milliseconds per series, considering both training and inference. Due to its zero-shot capabilities, TimeGPT outperforms traditional statistical methods and global models with total speed by orders of magnitude.\\n\\n# 7 Discussion and Future Research\\n\\nQuestion:\\nWhat is the architecture of TimeGPT, as described in Section 5.1 of the paper?\\n\\nAnswer:\\n', 'model': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'temperature': 0.0, 'max_tokens': 500, 'repetition_penalty': 1.2, 'stop': [\"I don't know.\"]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What is the architecture of TimeGPT, as described in Section 5.1 of the paper?\n",
       "\n",
       "**Risposta:** The architecture of TimeGPT consists of a Transformer-based time series model with self-attention mechanisms based on Vaswani et al. [2017]. It has an encoder-decoder structure with multiple layers, each containing residual connections and layer normalization. Additionally, local positional encoding is added to the input to enrich it. Finally, a linear layer maps the decoder's output to the forecasting window dimension. This design allows attention-based mechanisms to capture the diversity of past events and accurately predict potential future distributions. I do not have further details about the specifics of the number of layers or dimensions involved beyond what is mentioned here. However, according to the text, there isn't explicit mention of these specifications within section 5.1. Therefore, my knowledge stops at describing the overall architectural components without delving deeper due to lack of detail in the given context. \n",
       "\n",
       "Note: Since you asked me to ensure my responses were comprehensive but did not ask specifically how many times I should repeat myself, I chose to include additional contextual information while still being mindful of providing only the requested data. Please let me know if you'd like adjustments made!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await ask_question_naive(query_local2)\n",
    "\n",
    "end_time = time.time()\n",
    "time_local_naive2 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.3 Terza Query locale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GraphRAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: No community records added when building community context.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** How does the tokenization scheme of Lag-Llama work, as described in Section 4.1 of the paper?\n",
       "\n",
       "**Risposta:**\n",
       "**Tokenization Scheme of Lag-Llama**\n",
       "=====================================\n",
       "\n",
       "The tokenization scheme of Lag-Llama is described in Section 4.1 of the paper. According to the text, the tokenization scheme involves constructing lagged features from the prior values of the time series, constructed according to a specified set of appropriate lag indices.\n",
       "\n",
       "**Lag Indices**\n",
       "---------------\n",
       "\n",
       "The lag indices are a set of positive integers that specify the time intervals between the current and past values of a time series. The lag indices include quarterly, monthly, weekly, daily, hourly, and second-level frequencies.\n",
       "\n",
       "**Lag Operation**\n",
       "-----------------\n",
       "\n",
       "The lag operation is defined as follows:\n",
       "\n",
       "*Note that L refers to the list of lag indices, while L is the last lag index in the sorted list L*\n",
       "\n",
       "lag indices:\n",
       "\n",
       "- sec(t)\n",
       "- min(t)\n",
       "- month(t)\n",
       "\n",
       "time\n",
       "\n",
       "The lag operation is used to construct lagged features from the prior values of the time series.\n",
       "\n",
       "**Tokenization**\n",
       "----------------\n",
       "\n",
       "The tokenization scheme of Lag-Llama involves constructing lagged features from the prior values of the time series, constructed according to the specified set of lag indices. The lagged features are then used to create tokens that are passed through a shared linear projection layer that maps the features to the hidden dimension of the attention module.\n",
       "\n",
       "**Data References**\n",
       "-------------------\n",
       "\n",
       "This description is supported by the following data references:\n",
       "\n",
       "[Data: Sources (138); Relationships (773)]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await test_local_graph(query_local3)\n",
    "\n",
    "end_time = time.time()\n",
    "time_local_graph3 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG tradizionale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload inviato all'API: {'prompt': '\\nYou are a knowledgeable assistant specialized in answering questions based solely on the provided context. Provide a detailed and well-structured answer, including all relevant information from the context. Ensure your response is comprehensive, faithful to the context, and presented in clear, well-formed sentences. Do not add any information that is not present in the context. If the answer is not explicitly stated in the context, respond with \"I don\\'t know.\"\\n\\nContext:\\n# 4.1. Tokenization: Lag Features\\n\\nThe tokenization scheme of Lag-Llama involves constructing lagged features from the prior values of the time series, constructed according to a specified set of appropriate lag indices that include quarterly, monthly, weekly, daily, hourly, and second-level frequencies. Given a sorted set of positive lag indices L = {1, . . . , L}*, we define the lag operation:\\n\\n*Note that L refers to the list of lag indices, while L is the last lag index in the sorted list L\\n\\nlag indices:\\n\\n- sec(t)\\n- min(t)\\n- month(t)\\n\\ntime\\n\\nFigure 1: For a time series, we depict the tokenization at the timestep t of the value xt which contains lag features constructed using an example set of lag indices L, where each value in the vector is from the past of xt (in blue), and F possible temporal covariates (date-time features) constructed from timestamp t (red).\\n\\n¶This is since a history of L points in time is needed for all points in the context, starting from the first point in the context.\\n# Lag-Llama\\n\\nas in LLaMA (Touvron et al., 2023). After passing through the causally masked transformer layers, the model predicts the parameters ϕ of the forecast log prob distribution of the next timestep, where the parameters are output by a parametric distribution head, as described in Sec. 4.3. The negative log-likelihood of the predicted distribution of all predicted timesteps is minimized.\\n\\n# 4.5 MODEL ANALYSIS\\n\\n# Language Model Variants\\n\\nWe compare two representative backbones with varying capacities. Our results indicate that the scaling law retains after the LLM reprogramming. We adopt Llama-7B by default in its full capacity, which manifestly outperforms its 1/4 capacity variant by 14.5%. An average MSE reduction of 14.7% is observed over GPT-2, which slightly outperforms its variant GPT-2 (6) by 2.7%.\\n\\n# Cross-modality Alignment\\n\\n# 4.4. Value Scaling\\n\\nWhen training on a large corpus of time series data from different datasets and domains, each time series can be of different numerical magnitude. Since we pretrain a foundation model over such data, we utilize the scaling heuristic (Salinas et al., 2019b) where for each univariate window, we calculate its mean value μi = ∑t=1C xi / C and variance σi. We can then replace the time series xt with {(xit - μi) / σi}t=1. We also incorporate μi and σi as time independent real-valued covariates for each token, to give the model information of the statistics of the inputs, which we call summary statistics.\\n\\n# 4.5. Training Strategies\\n\\nWe employ a series of training strategies to effectively pre-train Lag-Llama on the corpus of datasets. Firstly, we find that employing a stratified sampling approach where the datasets in the corpus are weighed by the amount of total.\\n# Lag-Llama\\n\\n# 4.2. Lag-Llama Architecture\\n\\nLag-Llama’s architecture is based on the decoder-only transformer-based architecture LLaMA (Touvron et al., 2023). Fig. 2 shows a general schematic of this model with M decoder layers. A univariate sequence of length xi−L:C along with its covariates is tokenized by concatenating the covariate vectors to a sequence of C tokens xi1:C. These tokens are passed through a shared linear projection layer that maps the features to the hidden dimension of the attention module. Similar to in Touvron et al. (2023), Lag-Llama incorporates pre-normalization via the RMSNorm (Zhang & Sennrich, 2019) and Rotary Positional Encoding (RoPE) (Su et al., 2021) at each attention layer’s query and key representations.\\n\\n¶This is since a history of L points in time is needed for all points in the context, starting from the first point in the context.\\n# Lag-Llama\\n\\nQuestion:\\nHow does the tokenization scheme of Lag-Llama work, as described in Section 4.1 of the paper?\\n\\nAnswer:\\n', 'model': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'temperature': 0.0, 'max_tokens': 500, 'repetition_penalty': 1.2, 'stop': [\"I don't know.\"]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** How does the tokenization scheme of Lag-Llama work, as described in Section 4.1 of the paper?\n",
       "\n",
       "**Risposta:** According to Section 4.1, the tokenization scheme of Lag-Llama involves constructing lagged features from the prior values of the time series, constructed according to a specified set of appropriate lag indices that include quarterly, monthly, weekly, daily, hourly, and second-level frequencies. Specifically, given a sorted set of positive lag indices L = {1,..., L}, the lag operation constructs lag features from the prior values of the time series. This means that a history of L points in time is needed for all points in the context, starting from the first point in the context. Additionally, the lag indices used in the construction of lag features are defined as follows: sec(t), min(t), and month(t), where t represents the current time step. Figure 1 illustrates how the tokenization works at the timestep t, showing the lag features constructed using an example set of lag indices L, along with F possible temporal covariates (date-time features) constructed from timestamp t. Overall, the tokenization scheme of Lag-Llama aims to capture the historical dependencies between consecutive time steps in the input time series. I do not have more specific details about the implementation or mathematical formulation of the tokenization process beyond what has been mentioned in Section 4.1. However, it appears that the goal is to create a representation of the input time series that captures both short-term and long-term patterns and relationships."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await ask_question_naive(query_local3)\n",
    "\n",
    "end_time = time.time()\n",
    "time_local_naive3 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.4 Quarta Query locale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GraphRAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: No community records added when building community context.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What is the evaluation metric used to compare the performance of AnomalyBERT with previous works, as described in Section 4.2?\n",
       "\n",
       "**Risposta:**\n",
       "# Evaluation Metric for AnomalyBERT\n",
       "\n",
       "According to the provided text, the evaluation metric used to compare the performance of AnomalyBERT with previous works is the F1 score.\n",
       "\n",
       "## F1 Score\n",
       "\n",
       "The F1 score is a widely used metric in machine learning and data science to evaluate the performance of models, particularly in the context of anomaly detection. It is the harmonic mean of precision and recall, providing a balanced evaluation of a model's ability to correctly identify both true positives and true negatives.\n",
       "\n",
       "## Comparison with Previous Works\n",
       "\n",
       "The F1 score is used to compare the performance of AnomalyBERT with previous works, as described in Section 4.2. The results show that AnomalyBERT outperforms previous methods on five benchmark datasets, achieving improvement of up to 17.06% in F1 score.\n",
       "\n",
       "## Data References\n",
       "\n",
       "This information is supported by the following data references:\n",
       "\n",
       "* Section 4.2 of the text, which describes the evaluation metric used to compare the performance of AnomalyBERT with previous works.\n",
       "* The results table in Section 4.3, which shows the F1 score of AnomalyBERT and previous methods on five benchmark datasets.\n",
       "\n",
       "Note: The F1 score is also mentioned in the description of the entity \"F1 SCORE\" in the Entities table, but this is a separate entity from the evaluation metric used to compare the performance of AnomalyBERT with previous works."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await test_local_graph(query_local4)\n",
    "\n",
    "end_time = time.time()\n",
    "time_local_graph4 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG tradizionale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload inviato all'API: {'prompt': '\\nYou are a knowledgeable assistant specialized in answering questions based solely on the provided context. Provide a detailed and well-structured answer, including all relevant information from the context. Ensure your response is comprehensive, faithful to the context, and presented in clear, well-formed sentences. Do not add any information that is not present in the context. If the answer is not explicitly stated in the context, respond with \"I don\\'t know.\"\\n\\nContext:\\n# 4.4 MAIN RESULTS\\n\\nWe report the results of AnomalyBERT on the five real-world datasets introduced in Section 4.1, and compare them to those of the previous works. The reproduced evaluation scores are brought from Kim et al. (2022). In Table 2, we show that AnomalyBERT outperforms the previous methods on\\n# Presented at the ICLR 2023 workshop on Machine Learning for IoT: Datasets, Perception, and Understanding\\n\\n# Table 2: F1-scores for various anomaly detection methods and AnomalyBERT on five benchmark datasets.\\n\\nWe report the standard F1 and F1-scores after point adjustment (F1PA) following the protocol in Kim et al. (2022). Our method outperforms all existing methods with F1.\\n\\n# B VISUAL RESULTS\\n\\nWe visualize the prediction results of AnomalyBERT and present the 2D projections of the original data and latent features in the model. Similar to Figure 1, we select three abnormal windows in each of SWaT, WADI, and SMAP test sets and fetch the corresponding anomaly scores after the score prediction process. We then project the original data points and the last latent features from the abnormal windows into 2D planes using t-SNE. As shown in Figure 5, our method distinguishes anomalies successfully and separates abnormal data points from normal points well.\\n\\n# SWaT\\n\\n# WADI\\n\\n# SMAP\\n\\n# Figure 5: Visualization of anomaly score predictions on abnormal sequences in SWaT, WADI, and SMAP datasets.\\n\\n# 4.2.2 Anomaly Diagnosis\\n\\nWe use commonly used metrics to measure the diagnosis performance of all models [62]. HitRate@P% is the measure of how many ground truth dimensions have been included in the top candidates predicted by the model [45]. P% is the percentage of the ground truth dimensions for each timestamp, which we use to consider the top predicted candidates. For instance, if at timestamp t, if 2 dimensions are labeled anomalous in the ground truth, HitRate@100% would consider top 2 dimensions and HitRate@150% would consider 3 dimensions (100 and 150 are chosen based on prior work [62]). We also measure the Normalized Discounted Cumulative Gain (NDCG) [24]. NDCG@P% considers the same number of top predicted candidates as HitRate@P%.\\n\\n# 4.3 Results\\n\\n# Evaluation\\n\\nAnomaly scores (Eq. 2) exceeding a threshold δ are identified as anomalies. Performance is evaluated using the F1-score for threshold-dependent evaluation. Here, we follow [17] by setting δ to label a predefined proportion of data points as anomalies (0.5% for SMD, 1% for others). For threshold-independent analysis, we use AUC-ROC, AUC-PR, VUS-ROC, and VUS-PR metrics [21]. We exclude the point-adjustment method [22] due to its overestimation [23]. Our model is compared against baselines and state-of-the-arts models: LSTM [9], vanilla Transformer [17], USAD [13], PatchAD [12], AnomalyTrans [17], and DCdetector [10].\\n\\n1 https://github.com/Raminghorbanii/RESTAD\\n# RESTAD: REconstruction and Similarity based Transformer for time series Anomaly Detection\\n\\n# Table 1: Performance metrics of baselines and RESTAD on test sets.\\n\\nInitialization methods are denoted as (R) for Random and (K) for K-means. For all measures, a higher value indicates better anomaly detection performance.\\n\\n# 4 Experiments\\n\\nWe compare TranAD with state-of-the-art models for multivariate time-series anomaly detection, including MERLIN, LSTM-NDT (with autoencoder implementation from openGauss), DAGMM, OmniAnomaly, MSCRED, MAD-GAN, USAD, MTAD-GAT, CAE-M and GDN (with graph embedding implementation from GraphAn). For more details refer Section 2.1. We also tested the Isolation Forest method, but due to its low F1 scores, do not include the corresponding results in our discussion. Other classical methods have been omitted as well.\\n\\nQuestion:\\nWhat is the evaluation metric used to compare the performance of AnomalyBERT with previous works, as described in Section 4.2?\\n\\nAnswer:\\n', 'model': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'temperature': 0.0, 'max_tokens': 500, 'repetition_penalty': 1.2, 'stop': [\"I don't know.\"]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** What is the evaluation metric used to compare the performance of AnomalyBERT with previous works, as described in Section 4.2?\n",
       "\n",
       "**Risposta:** The evaluation metric used to compare the performance of AnomalyBERT with previous works is the F1-score. Specifically, it is mentioned that the standard F1 and F1-scores after point adjustment (F1PA) are reported, following the protocol in Kim et al. (2022). Additionally, it is noted that AnomalyBERT outperforms all existing methods with respect to this metric. However, no specific comparison or numerical values regarding other evaluation metrics such as AUC-ROC, AUC-PR, VUS-ROC, and VUS-PR are discussed in relation to comparing AnomalyBERT's performance with previous works within Section 4.2. \n",
       "\n",
       "However, according to section 4.3, when evaluating the performance of different models, several metrics like F1-score, AUC-ROC, AUC-PR, VUS-ROC, and VUS-PR are considered. But again, these comparisons were made between different models rather than specifically focusing on comparing AnomalyBERT’s performance with previous works within Section 4.2. Therefore, while multiple metrics might be utilized across sections, only the F1-score is directly associated with comparing AnomalyBERT with previous works within Section 4.2. \n",
       "Therefore, my final answer will focus on what was asked - the evaluation metric used to compare AnomalyBERT with previous works within Section 4.2.\n",
       "The correct answer is therefore: The F1-score."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await ask_question_naive(query_local4)\n",
    "\n",
    "end_time = time.time()\n",
    "time_local_naive4 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.5 Quinta Query locale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GraphRAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Domanda:** According to the paper 'Foundation Models for Time Series Analysis: A Tutorial and Survey', what is the primary difference between the proposed taxonomy and previous taxonomies?\n",
       "\n",
       "**Risposta:**\n",
       "**Primary Difference between Proposed Taxonomy and Previous Taxonomies**\n",
       "===========================================================\n",
       "\n",
       "According to the paper 'Foundation Models for Time Series Analysis: A Tutorial and Survey', the primary difference between the proposed taxonomy and previous taxonomies is the methodology-centric view. The proposed taxonomy delves deeper into the foundation models from the methodology perspective, focusing on their architectural designs, pre-training, and adaptation techniques.\n",
       "\n",
       "**Data: Taxonomy (1)**\n",
       "--------------------\n",
       "\n",
       "This is supported by the following data reference:\n",
       "\n",
       "* The paper states that the proposed taxonomy \"unfolds a structured and comprehensive classification to enhance the understanding of foundation models on time series analysis\" [Data: Taxonomy (1)].\n",
       "* The taxonomy is organized into four hierarchical levels, starting with the data category, followed by the model architecture, pre-training techniques, and finally, the application domain [Data: Taxonomy (1)].\n",
       "* The paper highlights that the proposed taxonomy distinguishes itself by delving deeper into the foundation models from the methodology perspective [Data: Taxonomy (1)].\n",
       "\n",
       "**Methodology-Centric View**\n",
       "---------------------------\n",
       "\n",
       "The proposed taxonomy's methodology-centric view is pivotal for researchers, providing valuable insights into the mechanisms of why and how foundation models show great potential for time series analysis.\n",
       "\n",
       "**Data: Taxonomy (1)**\n",
       "--------------------\n",
       "\n",
       "This is supported by the following data reference:\n",
       "\n",
       "* The paper states that the proposed taxonomy \"is pivotal for researchers, providing valuable insights into the mechanisms of why and how foundation models show great potential for time series analysis\" [Data: Taxonomy (1)].\n",
       "\n",
       "Overall, the primary difference between the proposed taxonomy and previous taxonomies is the methodology-centric view, which provides a deeper understanding of foundation models from the methodology perspective."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await test_local_graph(query_local5)\n",
    "\n",
    "end_time = time.time()\n",
    "time_local_graph5 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG tradizionale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload inviato all'API: {'prompt': '\\nYou are a knowledgeable assistant specialized in answering questions based solely on the provided context. Provide a detailed and well-structured answer, including all relevant information from the context. Ensure your response is comprehensive, faithful to the context, and presented in clear, well-formed sentences. Do not add any information that is not present in the context. If the answer is not explicitly stated in the context, respond with \"I don\\'t know.\"\\n\\nContext:\\n# 3. Taxonomy\\n\\nThe proposed taxonomy is illustrated in Figure 3, and the related works can be found in Table 2. The proposed taxonomy unfolds a structured and comprehensive classification to enhance the understanding of foundation models on time series analysis. It is organized into four hierarchical levels, starting with the data category, followed by the model architecture, pre-training techniques, and finally, the application domain. Unlike previous taxonomies, ours distinguishes itself by delving deeper into the foundation models from the methodology perspective, with a keen focus on their architectural designs, pre-training, and adaptation techniques. This method-centric view is pivotal for researchers, providing valuable insights into the mechanisms of why and how foundation models show great potential for time series analysis.\\n\\n# 4. Data Perspective\\n\\n- Comprehensive and up-to-date survey. We offer a comprehensive and up-to-date survey on foundation models for a wide spectrum of time series, encompassing standard time series, spatial time series, and other types (i.e., trajectories and events).\\n- Novel methodology-centric taxonomy. We introduce a novel taxonomy that offers a thorough analysis from a methodological standpoint on TSFMs with the first shot, enabling a full understanding of the mechanism on why and how FMs can achieve admirable performance in time series data.\\n- Future research opportunities. We discuss and highlight future avenues for enhancing time series analysis using foundation models, urging researchers to delve deeper into this area.\\n\\n# 2 BACKGROUND\\n\\n# Foundation Models.\\n\\nAuthor names are listed in alphabetical order.\\n# A decoder-only foundation model for time-series forecasting\\n\\n# A PREPRINT\\n\\nIn contrast to previous surveys, this manuscript incorporates the most extensive array of time series data types (see Table 1), spatial time series, as well as other types such as the trajectory and event. We further summarize the developmental roadmap of current TSFMs in Figure 1, in order to foster further innovations and understanding in the dynamic and ever-evolving landscape of TSFMs. In short, our major contributions lie in three aspects:\\n\\n# 4. Data Perspective\\n\\nIn this section, we explore advancements in TSFMs from various data perspectives: standard time series, spatial time series, and others. We further categorize our discussion within each subsection into task-oriented or general-purpose foundation models.\\n\\n# 4.1 Standard Time Series\\n\\nStandard time series possess diverse properties, including varying sampling rates and temporal patterns, which pose significant challenges in developing relevant FMs. These models aim to identify universal patterns within extensive time series data from varied sources, either to enhance specific tasks or for broad analysis.\\n\\nQuestion:\\nAccording to the paper \\'Foundation Models for Time Series Analysis: A Tutorial and Survey\\', what is the primary difference between the proposed taxonomy and previous taxonomies?\\n\\nAnswer:\\n', 'model': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'temperature': 0.0, 'max_tokens': 500, 'repetition_penalty': 1.2, 'stop': [\"I don't know.\"]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Domanda:** According to the paper 'Foundation Models for Time Series Analysis: A Tutorial and Survey', what is the primary difference between the proposed taxonomy and previous taxonomies?\n",
       "\n",
       "**Risposta:** Unlike previous taxonomies, the proposed taxonomy delves deeper into the foundation models from the methodology perspective, focusing on their architectural designs, pre-training, and adaptation techniques. This provides a more method-centric view, offering valuable insights into the mechanisms behind the effectiveness of foundation models for time series analysis. I don't know if there's anything else you'd like me to clarify about it!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "await ask_question_naive(query_local5)\n",
    "\n",
    "end_time = time.time()\n",
    "time_local_naive5 = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Confronto dei tempi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_local = {\n",
    "    'Domanda': [1, 2, 3, 4, 5],\n",
    "    'Time Naive Local': [time_local_naive1, time_local_naive2, time_local_naive3, time_local_naive4, time_local_naive5],\n",
    "    'Time GraphRAG Local': [time_local_graph1, time_local_graph2, time_local_graph3, time_local_graph4, time_local_graph5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Domanda  Time Naive Local  Time GraphRAG Local\n",
      "0        1          4.861367            15.411427\n",
      "1        2          4.925380            10.787562\n",
      "2        3          6.224860             7.304714\n",
      "3        4          6.420222             7.280919\n",
      "4        5          1.753119             8.774920\n"
     ]
    }
   ],
   "source": [
    "df_local = pd.DataFrame(data_local)\n",
    "\n",
    "print(df_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo medio Naive Local: 4.84 secondi\n",
      "Tempo medio GraphRAG Local: 9.91 secondi\n"
     ]
    }
   ],
   "source": [
    "mean_naive_local = df_local['Time Naive Local'].mean()\n",
    "mean_graph_local = df_local['Time GraphRAG Local'].mean()\n",
    "\n",
    "print(f\"Tempo medio Naive Local: {mean_naive_local:.2f} secondi\")\n",
    "print(f\"Tempo medio GraphRAG Local: {mean_graph_local:.2f} secondi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_local.plot(x='Domanda', y=['Time Naive Local', 'Time GraphRAG Local'], kind='bar', figsize=(10, 6))\n",
    "plt.title('Confronto Tempi Naive Local vs GraphRAG Local per Domanda')\n",
    "plt.ylabel('Tempo (secondi)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(['Naive Local', 'GraphRAG Local'], [mean_naive_local, mean_graph_local], color=['blue', 'green'])\n",
    "plt.title('Confronto Tempi Medi: Naive Local vs GraphRAG Local')\n",
    "plt.ylabel('Tempo Medio (secondi)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Approfondimento query GraphRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.4.1 (Python 3.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
